MLP.ipynb: defines a multilayer perceptron.

RNN.ipynb: defines an RNN. 

Transformer_token.ipynb: defines a transformer taking in token ids. For example, "She has a cat." => ["She", "has", "a", "cat"] => [0, 1, 2, 3]

Transformer_number.ipynb: defines a transformer taking in numbers. For example, multiplying two numbers.

Disclaimer: these models may have many variants. These implementations are what Ziming finds widely used and are as simple as possible. It is likely that for some tasks, you need to change the archetectures to make it work or interpretable.

