{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## need dependencies https://github.com/google-research/fast-soft-sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from .fast_soft_sort.pytorch_ops import soft_rank\n",
    "import tqdm.auto as tqdm\n",
    "from scipy.stats import spearmanr, kendalltau, rankdata\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import ElasticNet, Ridge\n",
    "\n",
    "\n",
    "def spearman_loss_fn(pred_rank, actual_rank, log_rank=False, weights=None):\n",
    "    if log_rank:\n",
    "        actual_rank = torch.log(actual_rank)\n",
    "        pred_rank = torch.log(pred_rank)\n",
    "    # squared norm of difference between predicted and actual rank\n",
    "    rank_diff_squared = (pred_rank - actual_rank) ** 2\n",
    "    if weights is not None:\n",
    "        sum_rank_diff_squared = (rank_diff_squared * weights).sum()\n",
    "    else:\n",
    "        sum_rank_diff_squared = rank_diff_squared.sum()\n",
    "    return 1 / len(actual_rank) * sum_rank_diff_squared\n",
    "\n",
    "\n",
    "class SpearmanRankProbeModel(nn.Module):\n",
    "    def __init__(self, d_model, reg_strength=0.0001, warm_start=None):\n",
    "        super(SpearmanRankProbeModel, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.reg_strength = reg_strength\n",
    "        self.feature_direction = nn.Linear(d_model, 1, bias=False)\n",
    "\n",
    "        if warm_start is not None:\n",
    "            self.feature_direction.weight.data = warm_start\n",
    "\n",
    "    def forward(self, X):\n",
    "        return soft_rank(\n",
    "            self.feature_direction(X).T,\n",
    "            regularization_strength=self.reg_strength\n",
    "        )\n",
    "\n",
    "\n",
    "class SpearmanRankProbe:\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim,\n",
    "        reg_strength=0.00001,\n",
    "        max_epochs=200,\n",
    "        lr=1e-3,\n",
    "        weight_decay=2e-1,\n",
    "        betas=(0.9, 0.98),\n",
    "        warm_start=None,\n",
    "    ):\n",
    "        self.probe = SpearmanRankProbeModel(\n",
    "            embedding_dim,\n",
    "            reg_strength=reg_strength,\n",
    "            warm_start=warm_start\n",
    "        )\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            self.probe.parameters(),\n",
    "            lr=lr, weight_decay=weight_decay, betas=betas\n",
    "        )\n",
    "\n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            self.optimizer, T_max=max_epochs, eta_min=5e-4)\n",
    "\n",
    "        self.max_epochs = max_epochs\n",
    "\n",
    "        self.iters_ = []\n",
    "        self.training_results = []\n",
    "\n",
    "        # TODO: potential features to add\n",
    "        # - early stopping\n",
    "\n",
    "    def fit(\n",
    "        self, data, ranking,\n",
    "        weights=None,\n",
    "        validation_data=None,\n",
    "        validation_ranking=None,\n",
    "        log_rank=False,\n",
    "        save_iterates=False,\n",
    "        debug=True,\n",
    "        verbose=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Train the rank probe model on the given data and ranking.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : torch.Tensor\n",
    "            The data to train on. Should be a 2D tensor of shape (n, d) where n is the number of\n",
    "            data points and d is the dimensionality of the data.\n",
    "        ranking : torch.Tensor\n",
    "            The ranking to train on. Should be a 1D tensor of shape (n,).\n",
    "        weights : torch.Tensor, optional\n",
    "            The weights to use for each data point, by default None (1 for all)\n",
    "        validation_data : torch.Tensor, optional\n",
    "            The data to use for validation in statistics, by default None (same as data)\n",
    "        validation_ranking : torch.Tensor, optional\n",
    "            The ranking to use for validation in statistics, by default None (same as ranking)\n",
    "        log_rank : bool, optional\n",
    "            Whether to take the log of the ranking before training, by default False\n",
    "        debug : bool, optional\n",
    "            Whether to save debug information, by default True\n",
    "        verbose : bool, optional\n",
    "            Whether to print pred_soft_rank debug information, by default False\n",
    "        \"\"\"\n",
    "        if weights is not None:\n",
    "            assert len(weights) == len(data)\n",
    "            weights /= weights.sum()\n",
    "\n",
    "        for epoch in tqdm.tqdm(range(self.max_epochs), disable=not verbose):\n",
    "            self.optimizer.zero_grad()\n",
    "            pred_soft_rank = self.probe(data)\n",
    "            loss = spearman_loss_fn(\n",
    "                pred_soft_rank, ranking, log_rank=log_rank, weights=weights)\n",
    "\n",
    "            # if len(self.iters_) > 0 and self.training_results[-1]['loss'] - loss.item() > 0:\n",
    "            #     break  # converged\n",
    "\n",
    "            # begin debug information\n",
    "            if debug:\n",
    "                weight_norm = self.probe.feature_direction.weight.data.norm().item()\n",
    "                spearman_coef = spearmanr(\n",
    "                    pred_soft_rank.detach().numpy().flatten(),\n",
    "                    ranking.detach().numpy().flatten()\n",
    "                ).correlation\n",
    "\n",
    "                feature_direction = self.probe.feature_direction.weight.data.clone().detach().squeeze()\n",
    "                prev_direction = self.iters_[-1].to(torch.float32) if len(self.iters_) > 0 \\\n",
    "                    else torch.zeros_like(feature_direction)\n",
    "\n",
    "                self.training_results.append({\n",
    "                    'epoch': epoch,\n",
    "                    'loss': loss.item(),\n",
    "                    'pred_variance': pred_soft_rank.var().item(),\n",
    "                    'pred_mean': pred_soft_rank.mean().item(),\n",
    "                    'pred_max': pred_soft_rank.max().item(),\n",
    "                    'pred_min': pred_soft_rank.min().item(),\n",
    "                    'train_spearman': spearman_coef,\n",
    "                    'lr': self.optimizer.param_groups[0]['lr'],\n",
    "                    'weight_norm': weight_norm,\n",
    "                    'weight_change': (feature_direction - prev_direction).norm().item() / weight_norm,\n",
    "                    'cosine_similarity': torch.cosine_similarity(\n",
    "                        feature_direction.unsqueeze(dim=0), prev_direction.unsqueeze(dim=0)).item()\n",
    "                })\n",
    "\n",
    "                if validation_data is not None and validation_ranking is not None:\n",
    "                    validation_spearman = spearmanr(\n",
    "                        validation_data @ feature_direction, validation_ranking).correlation\n",
    "                    self.training_results[-1]['validation_spearman'] = validation_spearman\n",
    "\n",
    "                # save weights\n",
    "                self.iters_.append(feature_direction.to(torch.float16))\n",
    "\n",
    "                if verbose:\n",
    "                    print(\n",
    "                        f'Epoch: {epoch} | Train Spearman: {spearman_coef} | Loss: {loss.item()} | Weight norm: {weight_norm}')\n",
    "            # end debug information\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "\n",
    "        if not save_iterates:\n",
    "            self.iters_ = self.iters_[-1:]\n",
    "\n",
    "        if pred_soft_rank.min().item() > 1.5:\n",
    "            print('Warning: soft ranks did not converge. Turn regularization down.')\n",
    "\n",
    "        # if len(self.iters_) == self.max_epochs:\n",
    "        #     print('Warning: max epochs reached without convergence.')\n",
    "\n",
    "    def score(self, data, ranking):\n",
    "        pred_soft_rank = self.probe(data)\n",
    "        return spearmanr(\n",
    "            pred_soft_rank.detach().numpy(),\n",
    "            ranking.detach().numpy()\n",
    "        ).correlation\n",
    "\n",
    "    def get_feature_direction(self):\n",
    "        return self.probe.feature_direction.weight.data.flatten().detach().cpu()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
