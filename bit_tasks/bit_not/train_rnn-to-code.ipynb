{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20efca18-cb26-4a61-8451-a7c4b09a11d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from model import RNN\n",
    "\n",
    "### Preparation ####\n",
    "\n",
    "# set random seed\n",
    "seed = 4\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# set precision and device\n",
    "torch.set_default_dtype(torch.float)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "### load dataset ###\n",
    "\n",
    "\n",
    "def load_data(mode='train'):\n",
    "    data = np.loadtxt('./data_{}.txt'.format(mode), dtype='str')\n",
    "    inputs = data[:,:1]\n",
    "    labels = data[:,1]\n",
    "\n",
    "    def strs2mat(strings):\n",
    "        num = strings.shape[0]\n",
    "        mat = []\n",
    "        for i in range(num):\n",
    "            mat.append([*strings[i]])\n",
    "        return mat\n",
    "\n",
    "    inputs_ = np.transpose(np.array([strs2mat(inputs[:,0])]), (1,2,0)).astype('float')\n",
    "    labels_ = np.array(strs2mat(labels))[:,:,np.newaxis].astype('float')\n",
    "\n",
    "    return inputs_, labels_\n",
    "\n",
    "inputs_train, labels_train = load_data(mode='train')\n",
    "inputs_test, labels_test = load_data(mode='test')\n",
    "\n",
    "inputs_train = torch.tensor(inputs_train, dtype=torch.float, requires_grad=True).to(device)\n",
    "labels_train = torch.tensor(labels_train, dtype=torch.float, requires_grad=True).to(device)\n",
    "inputs_test = torch.tensor(inputs_test, dtype=torch.float, requires_grad=True).to(device)\n",
    "labels_test = torch.tensor(labels_test, dtype=torch.float, requires_grad=True).to(device)\n",
    "\n",
    "def l1(model):\n",
    "    l1_reg = torch.tensor(0.).to(device)\n",
    "    for param in model.parameters():\n",
    "        l1_reg += torch.sum(torch.abs(param))\n",
    "    return l1_reg\n",
    "    \n",
    "\n",
    "model = RNN(hidden_dim=2,input_dim=1,device=device).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "777e3741-4601-436a-b4ca-19c3048e8075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0 | train loss: 2.47e-01 | test loss 2.40e-01 | train acc: 7.53e-01 | test acc: 7.60e-01 | reg: 6.76e+00 \n",
      "step = 200 | train loss: 4.23e-06 | test loss 4.26e-06 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 1.26e+01 \n",
      "step = 400 | train loss: 2.29e-06 | test loss 2.27e-06 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 1.26e+01 \n",
      "step = 600 | train loss: 1.91e-06 | test loss 1.88e-06 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 1.25e+01 \n",
      "step = 800 | train loss: 1.69e-06 | test loss 1.66e-06 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 1.25e+01 \n",
      "step = 1000 | train loss: 1.50e-06 | test loss 1.48e-06 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 1.24e+01 \n",
      "step = 1200 | train loss: 1.32e-06 | test loss 1.31e-06 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 1.24e+01 \n",
      "step = 1400 | train loss: 1.16e-06 | test loss 1.15e-06 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 1.24e+01 \n",
      "step = 1600 | train loss: 1.01e-06 | test loss 1.00e-06 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 1.23e+01 \n",
      "step = 1800 | train loss: 8.74e-07 | test loss 8.64e-07 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 1.23e+01 \n",
      "step = 2000 | train loss: 7.50e-07 | test loss 7.41e-07 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 1.22e+01 \n",
      "step = 2200 | train loss: 6.40e-07 | test loss 6.32e-07 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 1.22e+01 \n",
      "step = 2400 | train loss: 5.43e-07 | test loss 5.37e-07 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 1.21e+01 \n",
      "step = 2600 | train loss: 4.59e-07 | test loss 4.53e-07 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 1.21e+01 \n",
      "step = 2800 | train loss: 3.86e-07 | test loss 3.82e-07 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 1.20e+01 \n"
     ]
    }
   ],
   "source": [
    "### Training ###\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.0)\n",
    "steps = 3000\n",
    "log = 200\n",
    "lamb = 0e-4\n",
    "\n",
    "for step in range(steps):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pred_train = model(inputs_train)\n",
    "    loss_train = torch.mean((pred_train-labels_train)**2)\n",
    "    acc_train = 1-loss_train\n",
    "\n",
    "    pred_test = model(inputs_test)\n",
    "    loss_test = torch.mean((pred_test-labels_test)**2)\n",
    "    acc_test = 1-loss_test\n",
    "    \n",
    "    reg = l1(model)\n",
    "    loss = loss_train + lamb * reg\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % log == 0:\n",
    "        print(\"step = %d | train loss: %.2e | test loss %.2e | train acc: %.2e | test acc: %.2e | reg: %.2e \"%(step, loss_train.cpu().detach().numpy(), loss_test.cpu().detach().numpy(), acc_train.cpu().detach().numpy(), acc_test.cpu().detach().numpy(), reg.cpu().detach().numpy()))\n",
    "    \n",
    "torch.save(model.state_dict(), './model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cc878d1-61c6-422a-9be0-cea37566d051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (Wh): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (Wx): Linear(in_features=1, out_features=2, bias=True)\n",
       "  (Wy): Linear(in_features=2, out_features=1, bias=True)\n",
       "  (act): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41384b2d-fb8b-4194-948d-be8b5503e7ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs=inputs_train\n",
    "labels = labels_train\n",
    "seq_length=inputs_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59ce2df1-a53d-4c3b-9a27-491e7abd0cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = inputs.shape[0]\n",
    "hidden = torch.zeros(batch_size, model.hidden_dim).to(device)\n",
    "hiddens = []\n",
    "\n",
    "for i in range(seq_length):\n",
    "    hidden = model.act(model.Wh(hidden) + model.Wx(inputs[:,i,:]))\n",
    "    out = model.Wy(hidden)\n",
    "    hiddens.append(hidden.clone().cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e56a08e-37df-4066-8de6-6221ad452449",
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddens = np.transpose(np.array(hiddens), (1,0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c353b338-3805-4654-85d3-6316671e4272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(819, 6, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiddens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99b549d6-395a-46a4-92a0-04b279555d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fefc8b7e110>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "\n",
    "x = hiddens[:,:,0].reshape(-1,)\n",
    "y = hiddens[:,:,1].reshape(-1,)\n",
    "\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15aff584-1b54-49aa-993e-db451ca998eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "X = np.transpose(np.array([x,y]))\n",
    "kmeans = KMeans(n_clusters=4, random_state=0, n_init=\"auto\").fit(X)\n",
    "vectorlist = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fac2fa2-0c97-4298-86ed-9310c82298a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19545202, 0.17478946],\n",
       "       [0.67029047, 0.67741627],\n",
       "       [0.71906555, 0.62632185],\n",
       "       [0.16210759, 0.2094781 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36a945cf-653b-4b3b-85ff-4fc55a30bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find parallelogram\n",
    "\n",
    "# Tries to interpret 2^n vectors as n bits, defining an n-dimensional parallelogram\n",
    "# Max Tegmark Aug 25 2023\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy, itertools\n",
    "\n",
    "\n",
    "def bitstring2int(s): return int(s,2)\n",
    "\n",
    "def int2bitstring(n,i): \n",
    "    s = bin(i)[2:]\n",
    "    return \"\".join([\"0\" for j in range(n-len(s))])+s\n",
    "\n",
    "def str2int(lst): return list(map(int,lst))\n",
    "\n",
    "# Computes all 2^n bitstrings f length n:\n",
    "def allstrings(n): [int2bitstring(n,i) for i in range(2**n)]\n",
    "\n",
    "# Computes B-matrix whose rows are all 2^n bit strings of length n:\n",
    "def Bmatrix(n): \n",
    "    return np.array([str2int(list(int2bitstring(n,i))) for i in range(2**n)])\n",
    "\n",
    "def list2nN(lst):\n",
    "    N = len(lst)\n",
    "    n = int(np.log(N)/np.log(2))\n",
    "    if 2**n != N: \n",
    "        print(\"List length not power of 2: \",f,N,n)\n",
    "        exit()\n",
    "    return n,N                \n",
    "\n",
    "# Input:   a list of 2^n vectors\n",
    "# Output:  fitting error to model where these vectors form an n-dimensional parallelogram in canonical order\n",
    "# Demo:  vectorlist =[[10,20],[10,22],[11,21],[11,23]]\n",
    "def parallelogramFit(vectorlist):\n",
    "    n,N = list2nN(vectorlist)\n",
    "    A = np.array(vectorlist)\n",
    "    A = A - A[0] # WLOG 1st point is at the origin\n",
    "    B = Bmatrix(n)\n",
    "    BtB = B.T @ B\n",
    "    BBinv = np.linalg.inv(BtB)\n",
    "    X = BBinv @ B.T @ A\n",
    "    E = A - B @ X # Fitting error\n",
    "    error = np.trace(E.T @ E)/np.trace(A.T @ A) # Between & 1, where 0 = perfect\n",
    "    return error\n",
    "\n",
    "\n",
    "# Input:   a list of 2^n vectors\n",
    "# Output:  a list of 2^b bitstring of length n, labeling these vectors\n",
    "# Demo:  vectorlist =[[10,20],[10,22],[11,21],[11,23]]\n",
    "# Calls parallelogramFit for all permutations of the vectors and returns best fit.\n",
    "\n",
    "# Computes inverse permutation:\n",
    "def invperm(perm):\n",
    "    n = len(perm)\n",
    "    p = [0 for i in range(n)]\n",
    "    for i in range(n): p[perm[i]]=i\n",
    "    return p\n",
    "# Demo: invperm([1,2,3,0])\n",
    "\n",
    "def vecs2bits(vectorlist):\n",
    "    n,N = list2nN(vectorlist)\n",
    "    perms = list(itertools.permutations(range(N)))\n",
    "    besterror = 666.\n",
    "    for perm in itertools.permutations(range(N)):\n",
    "        A = [vectorlist[i] for i in perm]\n",
    "        error = parallelogramFit(A)\n",
    "        #print(perm,error)\n",
    "        if error < besterror:\n",
    "            error = besterror\n",
    "            bestperm = perm\n",
    "    B = Bmatrix(n)\n",
    "    p = invperm(bestperm)\n",
    "    bestB = np.array([B[p[i]] for i in range(N)]).astype(int)\n",
    "    return bestB,besterror\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0549d5b3-870a-443e-9cb5-07cc04dc07df",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_bits = 1 - vecs2bits(vectorlist.tolist())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcae2574-a7a1-4bc2-8b30-3a05f7f60f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(2**4)\n",
    "\n",
    "rs = []\n",
    "\n",
    "for i in range(4):\n",
    "    x, r = np.divmod(x, 2)\n",
    "    rs.append(r)\n",
    "    \n",
    "rs = np.transpose(np.array(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d379a6a6-3dce-4a57-8ff3-a7b43b090840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [1, 1, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [1, 0, 1, 0],\n",
       "       [0, 1, 1, 0],\n",
       "       [1, 1, 1, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [1, 0, 0, 1],\n",
       "       [0, 1, 0, 1],\n",
       "       [1, 1, 0, 1],\n",
       "       [0, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [0, 1, 1, 1],\n",
       "       [1, 1, 1, 1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6970f827-0005-4ffa-b823-eee1d669517e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2cf372a-6b3f-4873-9def-21a5a3032af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19545202, 0.17478946],\n",
       "       [0.67029047, 0.67741627],\n",
       "       [0.71906555, 0.62632185],\n",
       "       [0.16210759, 0.2094781 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f938824c-9178-461c-a9a8-d395ca91679c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.19545202 0.17478946]\n",
      " [0.71906555 0.62632185]\n",
      " [0.67029047 0.67741627]\n",
      " [0.16210759 0.2094781 ]\n",
      " [0.19545202 0.17478946]\n",
      " [0.71906555 0.62632185]\n",
      " [0.67029047 0.67741627]\n",
      " [0.16210759 0.2094781 ]\n",
      " [0.19545202 0.17478946]\n",
      " [0.71906555 0.62632185]\n",
      " [0.67029047 0.67741627]\n",
      " [0.16210759 0.2094781 ]\n",
      " [0.19545202 0.17478946]\n",
      " [0.71906555 0.62632185]\n",
      " [0.67029047 0.67741627]\n",
      " [0.16210759 0.2094781 ]]\n",
      "[[0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]]\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (16) must match the size of tensor b (32) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     11\u001b[0m x_flattened \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m hidden \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mact(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_flattened\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     14\u001b[0m out_bit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(out[:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     16\u001b[0m hidden_next_bit \u001b[38;5;241m=\u001b[39m cluster_bits[np\u001b[38;5;241m.\u001b[39margmin(np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(hidden\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()[np\u001b[38;5;241m.\u001b[39mnewaxis,:,:] \u001b[38;5;241m-\u001b[39m vectorlist[:,np\u001b[38;5;241m.\u001b[39mnewaxis,:], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (16) must match the size of tensor b (32) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "hidden = vectorlist[rs[:,0]*2 + rs[:,1]]\n",
    "print(hidden)\n",
    "x = rs[:,[2,3]]\n",
    "print(x)\n",
    "\n",
    "hidden = torch.tensor(hidden, dtype=torch.float, device=device)\n",
    "x = torch.tensor(x, dtype=torch.float, device=device)\n",
    "print(x.shape)\n",
    "out = model.Wy(hidden)\n",
    "\n",
    "x_flattened = x.reshape(32, -1)\n",
    "hidden = model.act(model.Wh(hidden) + model.Wx(x_flattened))\n",
    "\n",
    "out_bit = np.round(out[:,0].cpu().detach().numpy()).astype(int)\n",
    "\n",
    "hidden_next_bit = cluster_bits[np.argmin(np.linalg.norm(hidden.cpu().detach().numpy()[np.newaxis,:,:] - vectorlist[:,np.newaxis,:], axis=2), axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "88d3f444-d915-48fb-bda0-08de4c358819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "365c5dc0-7d1d-4034-8ce0-da3d5b8e4043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (hidden_current, x_current) => hidden_next; rs => hidden_next_bit\n",
    "# hidden_current = rs[:4, :2] => out_bit = out_bit[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "495a65f6-38e5-48c7-b856-979ee9cd9120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# three symbolic functions to be learned\n",
    "# out from h[0], h[1]\n",
    "# h[0] from last h[0], h[1], current x[0], x[1]\n",
    "# h[1] from last h[0], h[1], current x[0], x[1]\n",
    "\n",
    "\n",
    "# Tools for symbolic regression of boolean functions\n",
    "# Max Tegmark Aug 24-25 2023\n",
    "\n",
    "import time\n",
    "from math import log\n",
    "\n",
    "def bitstring2int(s): return int(s,2)\n",
    "\n",
    "def int2bitstring(n,i): \n",
    "    s = bin(i)[2:]\n",
    "    return \"\".join([\"0\" for j in range(n-len(s))])+s\n",
    "\n",
    "# A boolean function f is defined as a string f of length 2^n, say \"00010001\"\n",
    "# The argument list is defined as a string x length n ,say \"011\"\n",
    "# Returns char \"0\" or \"1\"\n",
    "def booleval(f,x):\n",
    "    n = len(x)\n",
    "    if len(f) != 2**n: \n",
    "        print(\"String length mismatch error: \",n,2**n,len(s))\n",
    "        exit()\n",
    "    i = bitstring2int(x)\n",
    "    return f[i]\n",
    "# DEMO: booleval(\"11111111\",\"111\")\n",
    "\n",
    "# Flip the ith bit in the bitstring n\n",
    "def flip_bit(x,i):\n",
    "    s = list(x)\n",
    "    s[i] = str(1-int(s[i]))\n",
    "    return \"\".join(s)\n",
    "# DEMO: flip_bit(\"11111111\",2)\n",
    "\n",
    "def f2nN(f):\n",
    "    N = len(f)\n",
    "    n = int(log(N)/log(2))\n",
    "    if 2**n != N: \n",
    "        print(\"String length not power of 2: \",f,N,n)\n",
    "        exit()\n",
    "    return n,N\n",
    "\n",
    "def bitsum(s): return sum([int(c) for c in s])\n",
    "\n",
    "def find_variables_used(f):\n",
    "    # Returns e.g. \"101\" if function f depends on x_0 & x_2 but not x_1\n",
    "    n,N = f2nN(f)\n",
    "    s = [\"0\" for i in range(n)]\n",
    "    for i in range(N):\n",
    "        x = int2bitstring(n,i)\n",
    "        for k in range(n):\n",
    "            if booleval(f,x) != booleval(f,flip_bit(x,k)): s[k] = \"1\"\n",
    "    return \"\".join(s)\n",
    "# DEMO: find_variables_used(\"01100110\") # x[1] XOR x[2]\n",
    "\n",
    "# Return the function f restricted to the only variables it depends on:\n",
    "def subfunc(f):\n",
    "    used = find_variables_used(f)\n",
    "    n = len(used)\n",
    "    vars = [i for i in range(n) if used[i]==\"1\"]\n",
    "    n1 = len(vars)\n",
    "    N1 = 2**n1\n",
    "    f1 = [\"0\" for i in range(N1)]\n",
    "    for i in range(N1):\n",
    "        x1 = int2bitstring(n1,i)\n",
    "        x  = [\"0\" for i in range(n)]\n",
    "        for k in range(n1): x[vars[k]] = x1[k]\n",
    "        f1[i] = booleval(f,\"\".join(x))\n",
    "    return f1,vars\n",
    "# DEMO: subfunc(\"01100110\") # x[1] XOR x[2]\n",
    "\n",
    "def parallelogram():\n",
    "    return\n",
    "\n",
    "def symmetricQ(f):\n",
    "    # Check if f is fully symmetric under all permutations of its variables, thus depending only on variable sum\n",
    "    # If so, returns string giving value taken for each bit sum, otherwise returns \"\".\n",
    "    # 2**(n+1) out of the 2**N functions are symmetric.\n",
    "    n,N = f2nN(f)\n",
    "    s = [\"-\" for i in range(n+1)]\n",
    "    for i in range(N):\n",
    "        x = int2bitstring(n,i)\n",
    "        k = bitsum(x)\n",
    "        c = booleval(f,x) \n",
    "        if s[k] != c:\n",
    "            if s[k] == \"-\": s[k] = c\n",
    "            else: return \"\"\n",
    "    return \"\".join(s)\n",
    "\n",
    "# Write x as boolean condition\"\n",
    "def x2dnf(x,varnames):\n",
    "    n = len(x)\n",
    "    return \" and \".join([[\"not \",\"\"][int(x[i])]+varnames[i] for i in range(n)])\n",
    "# Demo: x2dnf(\"110\",\"abc\") \n",
    "# returns \"a and b and not c\"\n",
    "\n",
    "# Write f in disjunctive normal form:\n",
    "def f2dnf(f,varnames):\n",
    "    n,N = f2nN(f)\n",
    "    return \" or \".join([\"(\"+x2dnf(int2bitstring(n,i),varnames)+\")\" for i in range(N) if f[i]==\"1\"])\n",
    "# Demo: f2dnf(\"01100110\",\"abc\") \n",
    "# returns \"a and b and not c\"\n",
    "\n",
    "# Checks if string of type \"010101010\":\n",
    "def parityQ(s):\n",
    "    x = [int(c) for c in s]\n",
    "    if x[0] != 0: return False\n",
    "    for i in range(len(x)-1):\n",
    "        if x[i]+x[i+1] != 1: return False\n",
    "    return True\n",
    "# DEMO: parityQ(\"01010\")\n",
    "    \n",
    "# Checks if string is sorted, like e.g. \"0000111\":\n",
    "def sortedQ(s):\n",
    "    for i in range(len(s)-1):\n",
    "        if s[i]>s[i+1]: return False\n",
    "    return True\n",
    "\n",
    "# Returns 4 if s=\"0000111\", returns -1 if not step function\n",
    "def stepupQ(s):\n",
    "    if not sortedQ(s): return -1\n",
    "    for i in range(len(s)): \n",
    "        if s[i]==\"1\": return i-1\n",
    "    return -1\n",
    "\n",
    "# Returns 4 if s=\"1111000\", returns -1 if not step function\n",
    "def stepdownQ(s):\n",
    "    if not sortedQ(\"\".join(reversed(s))): return -1\n",
    "    for i in range(len(s)): \n",
    "        if s[i]==\"0\": return i-1\n",
    "    return -1\n",
    "\n",
    "def symmfunc(s,varsum):\n",
    "    return \" or \".join([varsum+\"==\"+str(i) for i in range(len(s)) if s[i]==\"1\"])\n",
    "# Demo: symmfunc(\"1001\",\"abc\") \n",
    "# returns \"a+b+c==0 or a+b+c==3\"\n",
    "\n",
    "# Given a string s specifying how function depends on bit sum, return the formula:\n",
    "def symmetric_formula(s,varnames):\n",
    "    if len(varnames)==1 and s==\"10\": return \"not \"+varnames[0]\n",
    "    if parityQ(s): return \" xor \".join(varnames) # f is xor of all variables\n",
    "    varsum = \"+\".join(varnames)\n",
    "    i = stepupQ(s) \n",
    "    if i >= 0: return varsum+\">\"+str(i)\n",
    "    i = stepdownQ(s) \n",
    "    if i >= 0: return varsum+\"<\"+str(i+1)\n",
    "    return symmfunc(s,varsum)\n",
    "\n",
    "def formula(f):\n",
    "    f1,vars = subfunc(f)\n",
    "    varnames = [chr(97+i) for i in vars]\n",
    "    if varnames == []: return str(bool(int(f[0]))) # Function is a constant\n",
    "    formula1 = f2dnf(f1,varnames)\n",
    "    s = symmetricQ(f1)\n",
    "    if s == \"\": return formula1\n",
    "    formula2 = symmetric_formula(s,varnames)\n",
    "    if len(formula2)<len(formula1): formula1 = formula2 # Pick shortest formula\n",
    "    return formula1\n",
    "\n",
    "\n",
    "#def shortest_formula(f):\n",
    "    \n",
    "\n",
    "def demo1():\n",
    "    n = 3\n",
    "    N = 2**n\n",
    "    for i in range(2**N):\n",
    "        f = int2bitstring(N,i)\n",
    "        print(f+\": \"+formula(f))\n",
    "        #time.sleep(.5)\n",
    "    return\n",
    "\n",
    "def demo2():\n",
    "    print(formula(\"00000000\")) # False\n",
    "    print(formula(\"11111111\")) # True\n",
    "    print(formula(\"00001111\")) # a\n",
    "    print(formula(\"01100110\")) # b xor c\n",
    "    print(formula(\"01101001\")) # a xor b xor c\n",
    "    print(formula(\"01111111\")) # a+b+c==1 or a+b+c==2 or a+b+c==3 <=========\n",
    "    print(formula(\"00010111\")) # a+b+c==2 or a+b+c==3\n",
    "    print(formula(\"00000001\")) # a+b+c==3\n",
    "    print(formula(\"11101000\")) # a+b+c==0 or a+b+c==1  FAILS\n",
    "    print(formula(\"10000001\")) # a+b+c==0 or a+b+c==3\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0d3ba085-5fbb-467d-9a2a-c2740825a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (hidden_current, x_current) => hidden_next; rs => hidden_next_bit\n",
    "# hidden_current = rs[:4, :2] => out_bit = out_bit[:4]\n",
    "str_arr = np.zeros(16,dtype=int)\n",
    "indices = np.sum(rs * 2**np.array([3,2,1,0]), axis=1)\n",
    "str_arr[indices] = hidden_next_bit[:,0]\n",
    "string = \"\"\n",
    "for bit in list(str_arr):\n",
    "    string += str(bit)\n",
    "next_a_formula = formula(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7543cab3-4a22-4de9-b182-70d22c1dd0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c+d>0'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_a_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3402df4a-b597-4607-b7fb-f552482b6e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_arr = np.zeros(16,dtype=int)\n",
    "indices = np.sum(rs * 2**np.array([3,2,1,0]), axis=1)\n",
    "str_arr[indices] = hidden_next_bit[:,1]\n",
    "string = \"\"\n",
    "for bit in list(str_arr):\n",
    "    string += str(bit)\n",
    "next_b_formula = formula(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fa640887-269a-4637-88de-da744abbd513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c+d<2'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_b_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "996a04fe-2770-47b3-bb17-8f703139f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output bit\n",
    "str_arr = np.zeros(4,dtype=int)\n",
    "indices = np.sum(rs[:4,:2] * 2**np.array([1,0]), axis=1)\n",
    "str_arr[indices] = out_bit[:4]\n",
    "string = \"\"\n",
    "for bit in list(str_arr):\n",
    "    string += str(bit)\n",
    "out_formula = formula(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6642d052-e4dc-462c-8d97-f9f55b4e3598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(not a and not b) or (a and not b) or (a and b)'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "265c1ef0-3512-4a50-b9d9-d1698eba00db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c+d>0\n",
      "c+d<2\n",
      "(not a and not b) or (a and not b) or (a and b)\n"
     ]
    }
   ],
   "source": [
    "print(next_a_formula)\n",
    "print(next_b_formula)\n",
    "print(out_formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2bb99e0a-8231-4793-8d27-b968ab0a458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "#This is Vedang's version of the code to go from text to python\n",
    "def convert_logical_to_python(logical_expression):\n",
    "    \"\"\"\n",
    "    Converts a logical expression into its equivalent Python representation using NumPy bitwise operators.\n",
    "\n",
    "    Args:\n",
    "        logical_expression (str): The logical expression to be converted.\n",
    "\n",
    "    Returns:\n",
    "        str: The Python representation of the logical expression.\n",
    "    \"\"\"\n",
    "    \n",
    "    #This is the case we have a constraint\n",
    "    if \"<\" in logical_expression or \">\" in logical_expression:\n",
    "        return logical_expression\n",
    "    \n",
    "    def extract_elements(logical_expression):\n",
    "        \"\"\"\n",
    "        Extracts elements enclosed in parentheses from a logical expression.\n",
    "\n",
    "        Args:\n",
    "            logical_expression (str): The logical expression.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of elements inside parentheses.\n",
    "        \"\"\"\n",
    "        inside_elements = re.findall(r'\\((.*?)\\)', logical_expression)\n",
    "        return inside_elements\n",
    "\n",
    "    def apply_not(expression):\n",
    "        \"\"\"\n",
    "        Applies the NOT operation to a given expression.\n",
    "\n",
    "        Args:\n",
    "            expression (str): The expression to be negated.\n",
    "\n",
    "        Returns:\n",
    "            str: The negated expression.\n",
    "        \"\"\"\n",
    "        return f'1 - {expression}'\n",
    "\n",
    "    def convert_logic_operators(formula_split):\n",
    "        \"\"\"\n",
    "        Converts logical operators in a formula split into their equivalent Python representation.\n",
    "\n",
    "        Args:\n",
    "            formula_split (list): The split components of a logical formula.\n",
    "\n",
    "        Returns:\n",
    "            list: The list of converted components.\n",
    "        \"\"\"\n",
    "\n",
    "        operators_mapping = {'or': 'np.bitwise_or', 'and': 'np.bitwise_and', 'xor': 'np.bitwise_xor', 'not': apply_not}\n",
    "\n",
    "        formula_np = []\n",
    "        skip_next = False\n",
    "\n",
    "        for i, sub in enumerate(formula_split):\n",
    "            if skip_next:\n",
    "                skip_next = False\n",
    "                continue\n",
    "\n",
    "            mapped_sub = operators_mapping.get(sub, sub)\n",
    "            if callable(mapped_sub):\n",
    "                mapped_sub = mapped_sub(formula_split[i + 1])\n",
    "                skip_next = True\n",
    "\n",
    "            formula_np.append(mapped_sub)\n",
    "        return formula_np\n",
    "\n",
    "    def build_expression(formula_np):\n",
    "        \"\"\"\n",
    "        Builds a Python expression from a list of converted components.\n",
    "\n",
    "        Args:\n",
    "            formula_np (list): The list of converted components.\n",
    "\n",
    "        Returns:\n",
    "            str: The Python expression.\n",
    "        \"\"\"\n",
    "\n",
    "        expression_str = \"\"\n",
    "        i = 0\n",
    "\n",
    "        while i < len(formula_np):\n",
    "            sub = formula_np[i]\n",
    "\n",
    "            if sub in {'np.bitwise_and', 'np.bitwise_or', 'np.bitwise_xor'}:\n",
    "                expression_str = f'{sub}({expression_str},{formula_np[i+1]})'\n",
    "                i += 2\n",
    "            elif callable(sub):\n",
    "                expression_str = f'{sub}({formula_np[i+1]})'\n",
    "                i += 2\n",
    "            else:\n",
    "                expression_str += sub\n",
    "                i += 1\n",
    "\n",
    "        return expression_str\n",
    "\n",
    "    inside_elements = extract_elements(logical_expression)\n",
    "    to_or = [build_expression(convert_logic_operators(element.split())) for element in inside_elements]\n",
    "    \n",
    "    #If there are no subexpressions in () - we don't have to OR all of them ()\n",
    "    if len(inside_elements) == 0:\n",
    "        return build_expression(convert_logic_operators(logical_expression.split()))\n",
    "\n",
    "    def or_everything(expressions):\n",
    "        \"\"\"\n",
    "        Combines multiple expressions using the NumPy bitwise OR operation.\n",
    "\n",
    "        Args:\n",
    "            expressions (list): List of expressions to be combined.\n",
    "\n",
    "        Returns:\n",
    "            str: The final combined expression.\n",
    "        \"\"\"\n",
    "        if len(expressions) < 2:\n",
    "            return expressions[0]\n",
    "\n",
    "        final_expr = f\"np.bitwise_or({expressions[0]}, {expressions[1]})\"\n",
    "        for i in range(2, len(expressions)):\n",
    "            final_expr = f\"np.bitwise_or({final_expr}, {expressions[i]})\"\n",
    "        return final_expr\n",
    "    return or_everything(to_or)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "47358cf9-6907-430d-b41a-b032a7c724d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_a_formula_str = convert_logical_to_python(next_a_formula)\n",
    "next_b_formula_str = convert_logical_to_python(next_b_formula)\n",
    "out_formula_str = convert_logical_to_python(out_formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7440da37-e0fa-434a-89ea-9c15c040883f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c+d>0\n",
      "c+d<2\n",
      "np.bitwise_or(np.bitwise_or(np.bitwise_and(1 - a,1 - b), np.bitwise_and(a,1 - b)), np.bitwise_and(a,b))\n"
     ]
    }
   ],
   "source": [
    "print(next_a_formula_str)\n",
    "print(next_b_formula_str)\n",
    "print(out_formula_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "94336ba0-9a3e-4efc-8ac7-a6a98a173318",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = inputs.cpu().detach().numpy().astype(int)\n",
    "out_labels = labels.cpu().detach().numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "06871d25-e9ca-4c14-8c8d-538ec10dce21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xs are inputs, with shape (batch size, sequence length, 2)\n",
    "a = np.zeros(xs.shape[0],).astype(int)\n",
    "b = np.zeros(xs.shape[0],).astype(int)\n",
    "outs = []\n",
    "\n",
    "for i in range(xs.shape[1]):\n",
    "    c = xs[:,i,0]\n",
    "    d = xs[:,i,1]\n",
    "\n",
    "    exec('a = ' + next_a_formula_str)\n",
    "    exec('b = ' + next_b_formula_str)\n",
    "    exec('out = ' + out_formula_str)\n",
    "    outs.append(a)\n",
    "\n",
    "outs = np.transpose(np.array(outs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "84cec756-552f-4e20-905a-70821e9204a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_error = np.sum((1-out_labels[:,:,0] == outs))\n",
    "num_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6526451f-e59a-4085-a186-d7fcfec26841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
