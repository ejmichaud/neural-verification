{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20efca18-cb26-4a61-8451-a7c4b09a11d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from model import RNN\n",
    "\n",
    "### Preparation ####\n",
    "\n",
    "# set random seed\n",
    "seed = 3\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# set precision and device\n",
    "torch.set_default_dtype(torch.float)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device=\"cpu\"\n",
    "print(device)\n",
    "\n",
    "### load dataset ###\n",
    "\n",
    "\n",
    "def load_data(mode='train'):\n",
    "    data = np.loadtxt('./data_{}.txt'.format(mode), dtype='str')\n",
    "    inputs = data[:,:2]\n",
    "    labels = data[:,2]\n",
    "\n",
    "    def strs2mat(strings):\n",
    "        num = strings.shape[0]\n",
    "        mat = []\n",
    "        for i in range(num):\n",
    "            mat.append([*strings[i]])\n",
    "        return mat\n",
    "\n",
    "    inputs_ = np.transpose(np.array([strs2mat(inputs[:,0]), strs2mat(inputs[:,1])]), (1,2,0)).astype('float')\n",
    "    labels_ = np.array(strs2mat(labels))[:,:,np.newaxis].astype('float')\n",
    "\n",
    "    return inputs_, labels_\n",
    "\n",
    "inputs_train, labels_train = load_data(mode='train')\n",
    "inputs_test, labels_test = load_data(mode='test')\n",
    "\n",
    "inputs_train = torch.tensor(inputs_train, dtype=torch.float, requires_grad=True).to(device)\n",
    "labels_train = torch.tensor(labels_train, dtype=torch.float, requires_grad=True).to(device)\n",
    "inputs_test = torch.tensor(inputs_test, dtype=torch.float, requires_grad=True).to(device)\n",
    "labels_test = torch.tensor(labels_test, dtype=torch.float, requires_grad=True).to(device)\n",
    "\n",
    "def l1(model):\n",
    "    l1_reg = torch.tensor(0.).to(device)\n",
    "    for param in model.parameters():\n",
    "        l1_reg += torch.sum(torch.abs(param))\n",
    "    return l1_reg\n",
    "    \n",
    "\n",
    "model = RNN(hidden_dim=2, device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "777e3741-4601-436a-b4ca-19c3048e8075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0 | train loss: 1.80e+00 | test loss 1.80e+00 | train acc: -8.05e-01 | test acc: -8.03e-01 | reg: 6.06e+00 \n",
      "step = 200 | train loss: 1.27e-01 | test loss 1.31e-01 | train acc: 8.73e-01 | test acc: 8.69e-01 | reg: 7.45e+00 \n",
      "step = 400 | train loss: 3.19e-02 | test loss 3.39e-02 | train acc: 9.68e-01 | test acc: 9.66e-01 | reg: 1.26e+01 \n",
      "step = 600 | train loss: 6.58e-03 | test loss 6.46e-03 | train acc: 9.93e-01 | test acc: 9.94e-01 | reg: 1.57e+01 \n",
      "step = 800 | train loss: 2.95e-03 | test loss 2.77e-03 | train acc: 9.97e-01 | test acc: 9.97e-01 | reg: 1.70e+01 \n",
      "step = 1000 | train loss: 1.78e-03 | test loss 1.65e-03 | train acc: 9.98e-01 | test acc: 9.98e-01 | reg: 1.78e+01 \n",
      "step = 1200 | train loss: 1.22e-03 | test loss 1.13e-03 | train acc: 9.99e-01 | test acc: 9.99e-01 | reg: 1.84e+01 \n",
      "step = 1400 | train loss: 9.01e-04 | test loss 8.26e-04 | train acc: 9.99e-01 | test acc: 9.99e-01 | reg: 1.89e+01 \n",
      "step = 1600 | train loss: 6.94e-04 | test loss 6.33e-04 | train acc: 9.99e-01 | test acc: 9.99e-01 | reg: 1.94e+01 \n",
      "step = 1800 | train loss: 5.51e-04 | test loss 5.02e-04 | train acc: 9.99e-01 | test acc: 9.99e-01 | reg: 1.98e+01 \n",
      "step = 2000 | train loss: 4.47e-04 | test loss 4.06e-04 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 2.02e+01 \n",
      "step = 2200 | train loss: 3.68e-04 | test loss 3.34e-04 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 2.05e+01 \n",
      "step = 2400 | train loss: 3.07e-04 | test loss 2.78e-04 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 2.09e+01 \n",
      "step = 2600 | train loss: 2.58e-04 | test loss 2.34e-04 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 2.12e+01 \n",
      "step = 2800 | train loss: 2.17e-04 | test loss 1.97e-04 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 2.16e+01 \n"
     ]
    }
   ],
   "source": [
    "### Training ###\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.0)\n",
    "steps = 3000\n",
    "log = 200\n",
    "lamb = 0e-4\n",
    "\n",
    "for step in range(steps):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pred_train = model(inputs_train)\n",
    "    loss_train = torch.mean((pred_train-labels_train)**2)\n",
    "    acc_train = 1-loss_train\n",
    "\n",
    "    pred_test = model(inputs_test)\n",
    "    loss_test = torch.mean((pred_test-labels_test)**2)\n",
    "    acc_test = 1-loss_test\n",
    "    \n",
    "    reg = l1(model)\n",
    "    loss = loss_train + lamb * reg\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % log == 0:\n",
    "        print(\"step = %d | train loss: %.2e | test loss %.2e | train acc: %.2e | test acc: %.2e | reg: %.2e \"%(step, loss_train.cpu().detach().numpy(), loss_test.cpu().detach().numpy(), acc_train.cpu().detach().numpy(), acc_test.cpu().detach().numpy(), reg.cpu().detach().numpy()))\n",
    "    \n",
    "torch.save(model.state_dict(), './model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cc878d1-61c6-422a-9be0-cea37566d051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (Wh): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (Wx): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (Wy): Linear(in_features=2, out_features=1, bias=True)\n",
       "  (act): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41384b2d-fb8b-4194-948d-be8b5503e7ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs=inputs_train\n",
    "labels = labels_train\n",
    "seq_length=inputs_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59ce2df1-a53d-4c3b-9a27-491e7abd0cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = inputs.shape[0]\n",
    "hidden = torch.zeros(batch_size, model.hidden_dim).to(device)\n",
    "hiddens = []\n",
    "\n",
    "for i in range(seq_length):\n",
    "    hidden = model.act(model.Wh(hidden) + model.Wx(inputs[:,i,:]))\n",
    "    out = model.Wy(hidden)\n",
    "    hiddens.append(hidden.clone().cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e56a08e-37df-4066-8de6-6221ad452449",
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddens = np.transpose(np.array(hiddens), (1,0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c353b338-3805-4654-85d3-6316671e4272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(819, 1, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiddens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99b549d6-395a-46a4-92a0-04b279555d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f328fa9bf70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "\n",
    "x = hiddens[:,:,0].reshape(-1,)\n",
    "y = hiddens[:,:,1].reshape(-1,)\n",
    "\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15aff584-1b54-49aa-993e-db451ca998eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "X = np.transpose(np.array([x,y]))\n",
    "kmeans = KMeans(n_clusters=4, random_state=0, n_init=\"auto\").fit(X)\n",
    "vectorlist = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fac2fa2-0c97-4298-86ed-9310c82298a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.3790045e-01, 6.0962266e-01],\n",
       "       [2.6729748e-01, 2.0262957e-02],\n",
       "       [2.9030189e-01, 2.9169023e-04],\n",
       "       [2.5927007e-01, 2.1560565e-02]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36a945cf-653b-4b3b-85ff-4fc55a30bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find parallelogram\n",
    "\n",
    "# Tries to interpret 2^n vectors as n bits, defining an n-dimensional parallelogram\n",
    "# Max Tegmark Aug 25 2023\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy, itertools\n",
    "\n",
    "\n",
    "def bitstring2int(s): return int(s,2)\n",
    "\n",
    "def int2bitstring(n,i): \n",
    "    s = bin(i)[2:]\n",
    "    return \"\".join([\"0\" for j in range(n-len(s))])+s\n",
    "\n",
    "def str2int(lst): return list(map(int,lst))\n",
    "\n",
    "# Computes all 2^n bitstrings f length n:\n",
    "def allstrings(n): [int2bitstring(n,i) for i in range(2**n)]\n",
    "\n",
    "# Computes B-matrix whose rows are all 2^n bit strings of length n:\n",
    "def Bmatrix(n): \n",
    "    return np.array([str2int(list(int2bitstring(n,i))) for i in range(2**n)])\n",
    "\n",
    "def list2nN(lst):\n",
    "    N = len(lst)\n",
    "    n = int(np.log(N)/np.log(2))\n",
    "    if 2**n != N: \n",
    "        print(\"List length not power of 2: \",f,N,n)\n",
    "        exit()\n",
    "    return n,N                \n",
    "\n",
    "# Input:   a list of 2^n vectors\n",
    "# Output:  fitting error to model where these vectors form an n-dimensional parallelogram in canonical order\n",
    "# Demo:  vectorlist =[[10,20],[10,22],[11,21],[11,23]]\n",
    "def parallelogramFit(vectorlist):\n",
    "    n,N = list2nN(vectorlist)\n",
    "    A = np.array(vectorlist)\n",
    "    A = A - A[0] # WLOG 1st point is at the origin\n",
    "    B = Bmatrix(n)\n",
    "    BtB = B.T @ B\n",
    "    BBinv = np.linalg.inv(BtB)\n",
    "    X = BBinv @ B.T @ A\n",
    "    E = A - B @ X # Fitting error\n",
    "    error = np.trace(E.T @ E)/np.trace(A.T @ A) # Between & 1, where 0 = perfect\n",
    "    return error\n",
    "\n",
    "\n",
    "# Input:   a list of 2^n vectors\n",
    "# Output:  a list of 2^b bitstring of length n, labeling these vectors\n",
    "# Demo:  vectorlist =[[10,20],[10,22],[11,21],[11,23]]\n",
    "# Calls parallelogramFit for all permutations of the vectors and returns best fit.\n",
    "\n",
    "# Computes inverse permutation:\n",
    "def invperm(perm):\n",
    "    n = len(perm)\n",
    "    p = [0 for i in range(n)]\n",
    "    for i in range(n): p[perm[i]]=i\n",
    "    return p\n",
    "# Demo: invperm([1,2,3,0])\n",
    "\n",
    "def vecs2bits(vectorlist):\n",
    "    n,N = list2nN(vectorlist)\n",
    "    perms = list(itertools.permutations(range(N)))\n",
    "    besterror = 666.\n",
    "    for perm in itertools.permutations(range(N)):\n",
    "        A = [vectorlist[i] for i in perm]\n",
    "        error = parallelogramFit(A)\n",
    "        #print(perm,error)\n",
    "        if error < besterror:\n",
    "            error = besterror\n",
    "            bestperm = perm\n",
    "    B = Bmatrix(n)\n",
    "    p = invperm(bestperm)\n",
    "    bestB = np.array([B[p[i]] for i in range(N)]).astype(int)\n",
    "    return bestB,besterror\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0549d5b3-870a-443e-9cb5-07cc04dc07df",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_bits = 1 - vecs2bits(vectorlist.tolist())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcae2574-a7a1-4bc2-8b30-3a05f7f60f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(2**4)\n",
    "\n",
    "rs = []\n",
    "\n",
    "for i in range(4):\n",
    "    x, r = np.divmod(x, 2)\n",
    "    rs.append(r)\n",
    "    \n",
    "rs = np.transpose(np.array(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d379a6a6-3dce-4a57-8ff3-a7b43b090840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [1, 1, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [1, 0, 1, 0],\n",
       "       [0, 1, 1, 0],\n",
       "       [1, 1, 1, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [1, 0, 0, 1],\n",
       "       [0, 1, 0, 1],\n",
       "       [1, 1, 0, 1],\n",
       "       [0, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [0, 1, 1, 1],\n",
       "       [1, 1, 1, 1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6970f827-0005-4ffa-b823-eee1d669517e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2cf372a-6b3f-4873-9def-21a5a3032af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.3790045e-01, 6.0962266e-01],\n",
       "       [2.6729748e-01, 2.0262957e-02],\n",
       "       [2.9030189e-01, 2.9169023e-04],\n",
       "       [2.5927007e-01, 2.1560565e-02]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f938824c-9178-461c-a9a8-d395ca91679c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.3790045e-01 6.0962266e-01]\n",
      " [2.9030189e-01 2.9169023e-04]\n",
      " [2.6729748e-01 2.0262957e-02]\n",
      " [2.5927007e-01 2.1560565e-02]\n",
      " [2.3790045e-01 6.0962266e-01]\n",
      " [2.9030189e-01 2.9169023e-04]\n",
      " [2.6729748e-01 2.0262957e-02]\n",
      " [2.5927007e-01 2.1560565e-02]\n",
      " [2.3790045e-01 6.0962266e-01]\n",
      " [2.9030189e-01 2.9169023e-04]\n",
      " [2.6729748e-01 2.0262957e-02]\n",
      " [2.5927007e-01 2.1560565e-02]\n",
      " [2.3790045e-01 6.0962266e-01]\n",
      " [2.9030189e-01 2.9169023e-04]\n",
      " [2.6729748e-01 2.0262957e-02]\n",
      " [2.5927007e-01 2.1560565e-02]]\n",
      "[[0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]]\n",
      "torch.Size([16, 2])\n"
     ]
    }
   ],
   "source": [
    "hidden = vectorlist[rs[:,0]*2 + rs[:,1]]\n",
    "print(hidden)\n",
    "x = rs[:,[2,3]]\n",
    "print(x)\n",
    "\n",
    "hidden = torch.tensor(hidden, dtype=torch.float)\n",
    "x = torch.tensor(x, dtype=torch.float)\n",
    "print(x.shape)\n",
    "out = model.Wy(hidden)\n",
    "\n",
    "hidden = model.act(model.Wh(hidden) + model.Wx(x))\n",
    "\n",
    "out_bit = np.round(out[:,0].detach().numpy()).astype(int)\n",
    "\n",
    "hidden_next_bit = cluster_bits[np.argmin(np.linalg.norm(hidden.detach().numpy()[np.newaxis,:,:] - vectorlist[:,np.newaxis,:], axis=2), axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fff2e967-5c64-479f-a408-2d5f6e654451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2])\n"
     ]
    }
   ],
   "source": [
    "print(hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be9b85b5-5c97-4fa0-a478-012c38f1b422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d603443-f8c3-4734-9f95-a6b4f7170fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.3790045e-01 6.0962266e-01]\n",
      " [2.9030189e-01 2.9169023e-04]\n",
      " [2.6729748e-01 2.0262957e-02]\n",
      " [2.5927007e-01 2.1560565e-02]\n",
      " [2.3790045e-01 6.0962266e-01]\n",
      " [2.9030189e-01 2.9169023e-04]\n",
      " [2.6729748e-01 2.0262957e-02]\n",
      " [2.5927007e-01 2.1560565e-02]\n",
      " [2.3790045e-01 6.0962266e-01]\n",
      " [2.9030189e-01 2.9169023e-04]\n",
      " [2.6729748e-01 2.0262957e-02]\n",
      " [2.5927007e-01 2.1560565e-02]\n",
      " [2.3790045e-01 6.0962266e-01]\n",
      " [2.9030189e-01 2.9169023e-04]\n",
      " [2.6729748e-01 2.0262957e-02]\n",
      " [2.5927007e-01 2.1560565e-02]]\n",
      "[[0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]]\n",
      "torch.Size([16, 2])\n"
     ]
    }
   ],
   "source": [
    "hidden = vectorlist[rs[:,0]*2 + rs[:,1]]\n",
    "print(hidden)\n",
    "x = rs[:,[2,3]]\n",
    "print(x)\n",
    "\n",
    "hidden = torch.tensor(hidden, dtype=torch.float)\n",
    "x = torch.tensor(x, dtype=torch.float)\n",
    "print(x.shape)\n",
    "out = model.Wy(hidden)\n",
    "\n",
    "hidden = model.act(model.Wh(hidden) + model.Wx(x))\n",
    "\n",
    "out_bit = np.round(out[:,0].detach().numpy()).astype(int)\n",
    "\n",
    "hidden_next_bit = cluster_bits[np.argmin(np.linalg.norm(hidden.detach().numpy()[np.newaxis,:,:] - vectorlist[:,np.newaxis,:], axis=2), axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61f84670-a725-4a08-9e61-c9736b27dffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.3790045e-01, 6.0962266e-01],\n",
       "       [2.9030189e-01, 2.9169023e-04],\n",
       "       [2.6729748e-01, 2.0262957e-02],\n",
       "       [2.5927007e-01, 2.1560565e-02],\n",
       "       [2.3790045e-01, 6.0962266e-01],\n",
       "       [2.9030189e-01, 2.9169023e-04],\n",
       "       [2.6729748e-01, 2.0262957e-02],\n",
       "       [2.5927007e-01, 2.1560565e-02],\n",
       "       [2.3790045e-01, 6.0962266e-01],\n",
       "       [2.9030189e-01, 2.9169023e-04],\n",
       "       [2.6729748e-01, 2.0262957e-02],\n",
       "       [2.5927007e-01, 2.1560565e-02],\n",
       "       [2.3790045e-01, 6.0962266e-01],\n",
       "       [2.9030189e-01, 2.9169023e-04],\n",
       "       [2.6729748e-01, 2.0262957e-02],\n",
       "       [2.5927007e-01, 2.1560565e-02]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88d3f444-d915-48fb-bda0-08de4c358819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9770e-01, 1.8057e-04],\n",
       "        [2.5019e-01, 2.6715e-04],\n",
       "        [2.5113e-01, 2.6545e-04],\n",
       "        [2.5205e-01, 2.6586e-04],\n",
       "        [1.8017e-01, 1.2637e-02],\n",
       "        [2.2934e-01, 1.8586e-02],\n",
       "        [2.3022e-01, 1.8469e-02],\n",
       "        [2.3109e-01, 1.8498e-02],\n",
       "        [1.7413e-01, 1.3453e-02],\n",
       "        [2.2210e-01, 1.9778e-02],\n",
       "        [2.2297e-01, 1.9654e-02],\n",
       "        [2.2382e-01, 1.9685e-02],\n",
       "        [1.5828e-01, 4.9146e-01],\n",
       "        [2.0296e-01, 5.8846e-01],\n",
       "        [2.0377e-01, 5.8691e-01],\n",
       "        [2.0456e-01, 5.8729e-01]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "365c5dc0-7d1d-4034-8ce0-da3d5b8e4043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (hidden_current, x_current) => hidden_next; rs => hidden_next_bit\n",
    "# hidden_current = rs[:4, :2] => out_bit = out_bit[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "495a65f6-38e5-48c7-b856-979ee9cd9120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# three symbolic functions to be learned\n",
    "# out from h[0], h[1]\n",
    "# h[0] from last h[0], h[1], current x[0], x[1]\n",
    "# h[1] from last h[0], h[1], current x[0], x[1]\n",
    "\n",
    "\n",
    "# Tools for symbolic regression of boolean functions\n",
    "# Max Tegmark Aug 24-25 2023\n",
    "\n",
    "import time\n",
    "from math import log\n",
    "\n",
    "def bitstring2int(s): return int(s,2)\n",
    "\n",
    "def int2bitstring(n,i): \n",
    "    s = bin(i)[2:]\n",
    "    return \"\".join([\"0\" for j in range(n-len(s))])+s\n",
    "\n",
    "# A boolean function f is defined as a string f of length 2^n, say \"00010001\"\n",
    "# The argument list is defined as a string x length n ,say \"011\"\n",
    "# Returns char \"0\" or \"1\"\n",
    "def booleval(f,x):\n",
    "    n = len(x)\n",
    "    if len(f) != 2**n: \n",
    "        print(\"String length mismatch error: \",n,2**n,len(s))\n",
    "        exit()\n",
    "    i = bitstring2int(x)\n",
    "    return f[i]\n",
    "# DEMO: booleval(\"11111111\",\"111\")\n",
    "\n",
    "# Flip the ith bit in the bitstring n\n",
    "def flip_bit(x,i):\n",
    "    s = list(x)\n",
    "    s[i] = str(1-int(s[i]))\n",
    "    return \"\".join(s)\n",
    "# DEMO: flip_bit(\"11111111\",2)\n",
    "\n",
    "def f2nN(f):\n",
    "    N = len(f)\n",
    "    n = int(log(N)/log(2))\n",
    "    if 2**n != N: \n",
    "        print(\"String length not power of 2: \",f,N,n)\n",
    "        exit()\n",
    "    return n,N\n",
    "\n",
    "def bitsum(s): return sum([int(c) for c in s])\n",
    "\n",
    "def find_variables_used(f):\n",
    "    # Returns e.g. \"101\" if function f depends on x_0 & x_2 but not x_1\n",
    "    n,N = f2nN(f)\n",
    "    s = [\"0\" for i in range(n)]\n",
    "    for i in range(N):\n",
    "        x = int2bitstring(n,i)\n",
    "        for k in range(n):\n",
    "            if booleval(f,x) != booleval(f,flip_bit(x,k)): s[k] = \"1\"\n",
    "    return \"\".join(s)\n",
    "# DEMO: find_variables_used(\"01100110\") # x[1] XOR x[2]\n",
    "\n",
    "# Return the function f restricted to the only variables it depends on:\n",
    "def subfunc(f):\n",
    "    used = find_variables_used(f)\n",
    "    n = len(used)\n",
    "    vars = [i for i in range(n) if used[i]==\"1\"]\n",
    "    n1 = len(vars)\n",
    "    N1 = 2**n1\n",
    "    f1 = [\"0\" for i in range(N1)]\n",
    "    for i in range(N1):\n",
    "        x1 = int2bitstring(n1,i)\n",
    "        x  = [\"0\" for i in range(n)]\n",
    "        for k in range(n1): x[vars[k]] = x1[k]\n",
    "        f1[i] = booleval(f,\"\".join(x))\n",
    "    return f1,vars\n",
    "# DEMO: subfunc(\"01100110\") # x[1] XOR x[2]\n",
    "\n",
    "def parallelogram():\n",
    "    return\n",
    "\n",
    "def symmetricQ(f):\n",
    "    # Check if f is fully symmetric under all permutations of its variables, thus depending only on variable sum\n",
    "    # If so, returns string giving value taken for each bit sum, otherwise returns \"\".\n",
    "    # 2**(n+1) out of the 2**N functions are symmetric.\n",
    "    n,N = f2nN(f)\n",
    "    s = [\"-\" for i in range(n+1)]\n",
    "    for i in range(N):\n",
    "        x = int2bitstring(n,i)\n",
    "        k = bitsum(x)\n",
    "        c = booleval(f,x) \n",
    "        if s[k] != c:\n",
    "            if s[k] == \"-\": s[k] = c\n",
    "            else: return \"\"\n",
    "    return \"\".join(s)\n",
    "\n",
    "# Write x as boolean condition\"\n",
    "def x2dnf(x,varnames):\n",
    "    n = len(x)\n",
    "    return \" and \".join([[\"not \",\"\"][int(x[i])]+varnames[i] for i in range(n)])\n",
    "# Demo: x2dnf(\"110\",\"abc\") \n",
    "# returns \"a and b and not c\"\n",
    "\n",
    "# Write f in disjunctive normal form:\n",
    "def f2dnf(f,varnames):\n",
    "    n,N = f2nN(f)\n",
    "    return \" or \".join([\"(\"+x2dnf(int2bitstring(n,i),varnames)+\")\" for i in range(N) if f[i]==\"1\"])\n",
    "# Demo: f2dnf(\"01100110\",\"abc\") \n",
    "# returns \"a and b and not c\"\n",
    "\n",
    "# Checks if string of type \"010101010\":\n",
    "def parityQ(s):\n",
    "    x = [int(c) for c in s]\n",
    "    if x[0] != 0: return False\n",
    "    for i in range(len(x)-1):\n",
    "        if x[i]+x[i+1] != 1: return False\n",
    "    return True\n",
    "# DEMO: parityQ(\"01010\")\n",
    "    \n",
    "# Checks if string is sorted, like e.g. \"0000111\":\n",
    "def sortedQ(s):\n",
    "    for i in range(len(s)-1):\n",
    "        if s[i]>s[i+1]: return False\n",
    "    return True\n",
    "\n",
    "# Returns 4 if s=\"0000111\", returns -1 if not step function\n",
    "def stepupQ(s):\n",
    "    if not sortedQ(s): return -1\n",
    "    for i in range(len(s)): \n",
    "        if s[i]==\"1\": return i-1\n",
    "    return -1\n",
    "\n",
    "# Returns 4 if s=\"1111000\", returns -1 if not step function\n",
    "def stepdownQ(s):\n",
    "    if not sortedQ(\"\".join(reversed(s))): return -1\n",
    "    for i in range(len(s)): \n",
    "        if s[i]==\"0\": return i-1\n",
    "    return -1\n",
    "\n",
    "def symmfunc(s,varsum):\n",
    "    return \" or \".join([varsum+\"==\"+str(i) for i in range(len(s)) if s[i]==\"1\"])\n",
    "# Demo: symmfunc(\"1001\",\"abc\") \n",
    "# returns \"a+b+c==0 or a+b+c==3\"\n",
    "\n",
    "# Given a string s specifying how function depends on bit sum, return the formula:\n",
    "def symmetric_formula(s,varnames):\n",
    "    if len(varnames)==1 and s==\"10\": return \"not \"+varnames[0]\n",
    "    if parityQ(s): return \" xor \".join(varnames) # f is xor of all variables\n",
    "    varsum = \"+\".join(varnames)\n",
    "    i = stepupQ(s) \n",
    "    if i >= 0: return varsum+\">\"+str(i)\n",
    "    i = stepdownQ(s) \n",
    "    if i >= 0: return varsum+\"<\"+str(i+1)\n",
    "    return symmfunc(s,varsum)\n",
    "\n",
    "def formula(f):\n",
    "    f1,vars = subfunc(f)\n",
    "    varnames = [chr(97+i) for i in vars]\n",
    "    if varnames == []: return str(bool(int(f[0]))) # Function is a constant\n",
    "    formula1 = f2dnf(f1,varnames)\n",
    "    s = symmetricQ(f1)\n",
    "    if s == \"\": return formula1\n",
    "    formula2 = symmetric_formula(s,varnames)\n",
    "    if len(formula2)<len(formula1): formula1 = formula2 # Pick shortest formula\n",
    "    return formula1\n",
    "\n",
    "\n",
    "#def shortest_formula(f):\n",
    "    \n",
    "\n",
    "def demo1():\n",
    "    n = 3\n",
    "    N = 2**n\n",
    "    for i in range(2**N):\n",
    "        f = int2bitstring(N,i)\n",
    "        print(f+\": \"+formula(f))\n",
    "        #time.sleep(.5)\n",
    "    return\n",
    "\n",
    "def demo2():\n",
    "    print(formula(\"00000000\")) # False\n",
    "    print(formula(\"11111111\")) # True\n",
    "    print(formula(\"00001111\")) # a\n",
    "    print(formula(\"01100110\")) # b xor c\n",
    "    print(formula(\"01101001\")) # a xor b xor c\n",
    "    print(formula(\"01111111\")) # a+b+c==1 or a+b+c==2 or a+b+c==3 <=========\n",
    "    print(formula(\"00010111\")) # a+b+c==2 or a+b+c==3\n",
    "    print(formula(\"00000001\")) # a+b+c==3\n",
    "    print(formula(\"11101000\")) # a+b+c==0 or a+b+c==1  FAILS\n",
    "    print(formula(\"10000001\")) # a+b+c==0 or a+b+c==3\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d3ba085-5fbb-467d-9a2a-c2740825a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (hidden_current, x_current) => hidden_next; rs => hidden_next_bit\n",
    "# hidden_current = rs[:4, :2] => out_bit = out_bit[:4]\n",
    "str_arr = np.zeros(16,dtype=int)\n",
    "indices = np.sum(rs * 2**np.array([3,2,1,0]), axis=1)\n",
    "str_arr[indices] = hidden_next_bit[:,0]\n",
    "string = \"\"\n",
    "for bit in list(str_arr):\n",
    "    string += str(bit)\n",
    "next_a_formula = formula(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7543cab3-4a22-4de9-b182-70d22c1dd0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c+d<2'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_a_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3402df4a-b597-4607-b7fb-f552482b6e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_arr = np.zeros(16,dtype=int)\n",
    "indices = np.sum(rs * 2**np.array([3,2,1,0]), axis=1)\n",
    "str_arr[indices] = hidden_next_bit[:,1]\n",
    "string = \"\"\n",
    "for bit in list(str_arr):\n",
    "    string += str(bit)\n",
    "next_b_formula = formula(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa640887-269a-4637-88de-da744abbd513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c+d<2'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_b_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "996a04fe-2770-47b3-bb17-8f703139f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output bit\n",
    "str_arr = np.zeros(4,dtype=int)\n",
    "indices = np.sum(rs[:4,:2] * 2**np.array([1,0]), axis=1)\n",
    "str_arr[indices] = out_bit[:4]\n",
    "string = \"\"\n",
    "for bit in list(str_arr):\n",
    "    string += str(bit)\n",
    "out_formula = formula(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6642d052-e4dc-462c-8d97-f9f55b4e3598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a+b<1'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "265c1ef0-3512-4a50-b9d9-d1698eba00db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c+d<2\n",
      "c+d<2\n",
      "a+b<1\n"
     ]
    }
   ],
   "source": [
    "print(next_a_formula)\n",
    "print(next_b_formula)\n",
    "print(out_formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2bb99e0a-8231-4793-8d27-b968ab0a458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "#This is Vedang's version of the code to go from text to python\n",
    "def convert_logical_to_python(logical_expression):\n",
    "    \"\"\"\n",
    "    Converts a logical expression into its equivalent Python representation using NumPy bitwise operators.\n",
    "\n",
    "    Args:\n",
    "        logical_expression (str): The logical expression to be converted.\n",
    "\n",
    "    Returns:\n",
    "        str: The Python representation of the logical expression.\n",
    "    \"\"\"\n",
    "    \n",
    "    #This is the case we have a constraint\n",
    "    if \"<\" in logical_expression or \">\" in logical_expression:\n",
    "        return logical_expression\n",
    "    \n",
    "    def extract_elements(logical_expression):\n",
    "        \"\"\"\n",
    "        Extracts elements enclosed in parentheses from a logical expression.\n",
    "\n",
    "        Args:\n",
    "            logical_expression (str): The logical expression.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of elements inside parentheses.\n",
    "        \"\"\"\n",
    "        inside_elements = re.findall(r'\\((.*?)\\)', logical_expression)\n",
    "        return inside_elements\n",
    "\n",
    "    def apply_not(expression):\n",
    "        \"\"\"\n",
    "        Applies the NOT operation to a given expression.\n",
    "\n",
    "        Args:\n",
    "            expression (str): The expression to be negated.\n",
    "\n",
    "        Returns:\n",
    "            str: The negated expression.\n",
    "        \"\"\"\n",
    "        return f'1 - {expression}'\n",
    "\n",
    "    def convert_logic_operators(formula_split):\n",
    "        \"\"\"\n",
    "        Converts logical operators in a formula split into their equivalent Python representation.\n",
    "\n",
    "        Args:\n",
    "            formula_split (list): The split components of a logical formula.\n",
    "\n",
    "        Returns:\n",
    "            list: The list of converted components.\n",
    "        \"\"\"\n",
    "\n",
    "        operators_mapping = {'or': 'np.bitwise_or', 'and': 'np.bitwise_and', 'xor': 'np.bitwise_xor', 'not': apply_not}\n",
    "\n",
    "        formula_np = []\n",
    "        skip_next = False\n",
    "\n",
    "        for i, sub in enumerate(formula_split):\n",
    "            if skip_next:\n",
    "                skip_next = False\n",
    "                continue\n",
    "\n",
    "            mapped_sub = operators_mapping.get(sub, sub)\n",
    "            if callable(mapped_sub):\n",
    "                mapped_sub = mapped_sub(formula_split[i + 1])\n",
    "                skip_next = True\n",
    "\n",
    "            formula_np.append(mapped_sub)\n",
    "        return formula_np\n",
    "\n",
    "    def build_expression(formula_np):\n",
    "        \"\"\"\n",
    "        Builds a Python expression from a list of converted components.\n",
    "\n",
    "        Args:\n",
    "            formula_np (list): The list of converted components.\n",
    "\n",
    "        Returns:\n",
    "            str: The Python expression.\n",
    "        \"\"\"\n",
    "\n",
    "        expression_str = \"\"\n",
    "        i = 0\n",
    "\n",
    "        while i < len(formula_np):\n",
    "            sub = formula_np[i]\n",
    "\n",
    "            if sub in {'np.bitwise_and', 'np.bitwise_or', 'np.bitwise_xor'}:\n",
    "                expression_str = f'{sub}({expression_str},{formula_np[i+1]})'\n",
    "                i += 2\n",
    "            elif callable(sub):\n",
    "                expression_str = f'{sub}({formula_np[i+1]})'\n",
    "                i += 2\n",
    "            else:\n",
    "                expression_str += sub\n",
    "                i += 1\n",
    "\n",
    "        return expression_str\n",
    "\n",
    "    inside_elements = extract_elements(logical_expression)\n",
    "    to_or = [build_expression(convert_logic_operators(element.split())) for element in inside_elements]\n",
    "    \n",
    "    #If there are no subexpressions in () - we don't have to OR all of them ()\n",
    "    if len(inside_elements) == 0:\n",
    "        return build_expression(convert_logic_operators(logical_expression.split()))\n",
    "\n",
    "    def or_everything(expressions):\n",
    "        \"\"\"\n",
    "        Combines multiple expressions using the NumPy bitwise OR operation.\n",
    "\n",
    "        Args:\n",
    "            expressions (list): List of expressions to be combined.\n",
    "\n",
    "        Returns:\n",
    "            str: The final combined expression.\n",
    "        \"\"\"\n",
    "        if len(expressions) < 2:\n",
    "            return expressions[0]\n",
    "\n",
    "        final_expr = f\"np.bitwise_or({expressions[0]}, {expressions[1]})\"\n",
    "        for i in range(2, len(expressions)):\n",
    "            final_expr = f\"np.bitwise_or({final_expr}, {expressions[i]})\"\n",
    "        return final_expr\n",
    "    return or_everything(to_or)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47358cf9-6907-430d-b41a-b032a7c724d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_a_formula_str = convert_logical_to_python(next_a_formula)\n",
    "next_b_formula_str = convert_logical_to_python(next_b_formula)\n",
    "out_formula_str = convert_logical_to_python(out_formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7440da37-e0fa-434a-89ea-9c15c040883f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c+d<2\n",
      "c+d<2\n",
      "a+b<1\n"
     ]
    }
   ],
   "source": [
    "print(next_a_formula_str)\n",
    "print(next_b_formula_str)\n",
    "print(out_formula_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94336ba0-9a3e-4efc-8ac7-a6a98a173318",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = inputs.detach().numpy().astype(int)\n",
    "out_labels = labels.detach().numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06871d25-e9ca-4c14-8c8d-538ec10dce21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xs are inputs, with shape (batch size, sequence length, 2)\n",
    "a = np.zeros(xs.shape[0],).astype(int)\n",
    "b = np.zeros(xs.shape[0],).astype(int)\n",
    "outs = []\n",
    "\n",
    "for i in range(xs.shape[1]):\n",
    "    c = xs[:,i,0]\n",
    "    d = xs[:,i,1]\n",
    "\n",
    "    exec('a = ' + next_a_formula_str)\n",
    "    exec('b = ' + next_b_formula_str)\n",
    "    exec('out = ' + out_formula_str)\n",
    "    outs.append(a)\n",
    "\n",
    "outs = np.transpose(np.array(outs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84cec756-552f-4e20-905a-70821e9204a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hack/Error\n",
    "#This is supposed to be 1-out_labels[:,:,0] but somehow that isnt working\n",
    "num_error = np.sum((out_labels[:,:,0] == outs))\n",
    "num_error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
