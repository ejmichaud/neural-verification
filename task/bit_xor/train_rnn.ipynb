{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55be3a15-9b96-415d-9188-01ca9b930dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "step = 0 | train loss: 2.45e+00 | test loss 2.40e+00 | train acc: -1.45e+00 | test acc: -1.40e+00 | reg: 6.06e+00 \n",
      "step = 200 | train loss: 2.36e-01 | test loss 2.38e-01 | train acc: 7.64e-01 | test acc: 7.62e-01 | reg: 7.36e+00 \n",
      "step = 400 | train loss: 2.09e-01 | test loss 2.13e-01 | train acc: 7.91e-01 | test acc: 7.87e-01 | reg: 9.69e+00 \n",
      "step = 600 | train loss: 1.83e-01 | test loss 1.88e-01 | train acc: 8.17e-01 | test acc: 8.12e-01 | reg: 1.23e+01 \n",
      "step = 800 | train loss: 1.72e-01 | test loss 1.77e-01 | train acc: 8.28e-01 | test acc: 8.23e-01 | reg: 1.42e+01 \n",
      "step = 1000 | train loss: 1.67e-01 | test loss 1.72e-01 | train acc: 8.33e-01 | test acc: 8.28e-01 | reg: 1.58e+01 \n",
      "step = 1200 | train loss: 1.29e-01 | test loss 1.33e-01 | train acc: 8.71e-01 | test acc: 8.67e-01 | reg: 1.93e+01 \n",
      "step = 1400 | train loss: 1.51e-02 | test loss 1.55e-02 | train acc: 9.85e-01 | test acc: 9.85e-01 | reg: 2.65e+01 \n",
      "step = 1600 | train loss: 7.66e-05 | test loss 7.81e-05 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 2.91e+01 \n",
      "step = 1800 | train loss: 9.72e-08 | test loss 9.89e-08 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 2.93e+01 \n",
      "step = 2000 | train loss: 4.01e-11 | test loss 4.07e-11 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 2.93e+01 \n",
      "step = 2200 | train loss: 1.27e-12 | test loss 1.29e-12 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 2.93e+01 \n",
      "step = 2400 | train loss: 1.11e-12 | test loss 1.14e-12 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 2.93e+01 \n",
      "step = 2600 | train loss: 7.24e-13 | test loss 7.41e-13 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 2.93e+01 \n",
      "step = 2800 | train loss: 7.24e-13 | test loss 7.41e-13 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 2.93e+01 \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from model import RNN\n",
    "\n",
    "### Preparation ####\n",
    "\n",
    "# set random seed\n",
    "seed = 3\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# set precision and device\n",
    "torch.set_default_dtype(torch.float)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "### load dataset ###\n",
    "\n",
    "def load_data(mode='train'):\n",
    "    data = np.loadtxt('./data_{}.txt'.format(mode), dtype='str')\n",
    "    inputs = data[:,:2]\n",
    "    labels = data[:,2]\n",
    "\n",
    "    def strs2mat(strings):\n",
    "        num = strings.shape[0]\n",
    "        mat = []\n",
    "        for i in range(num):\n",
    "            mat.append([*strings[i]])\n",
    "        return mat\n",
    "\n",
    "    inputs_ = np.transpose(np.array([strs2mat(inputs[:,0]), strs2mat(inputs[:,1])]), (1,2,0)).astype('float')\n",
    "    labels_ = np.array(strs2mat(labels))[:,:,np.newaxis].astype('float')\n",
    "\n",
    "    return inputs_, labels_\n",
    "\n",
    "inputs_train, labels_train = load_data(mode='train')\n",
    "inputs_test, labels_test = load_data(mode='test')\n",
    "\n",
    "inputs_train = torch.tensor(inputs_train, dtype=torch.float, requires_grad=True).to(device)\n",
    "labels_train = torch.tensor(labels_train, dtype=torch.float, requires_grad=True).to(device)\n",
    "inputs_test = torch.tensor(inputs_test, dtype=torch.float, requires_grad=True).to(device)\n",
    "labels_test = torch.tensor(labels_test, dtype=torch.float, requires_grad=True).to(device)\n",
    "\n",
    "def l1(model):\n",
    "    l1_reg = torch.tensor(0.).to(device)\n",
    "    for param in model.parameters():\n",
    "        l1_reg += torch.sum(torch.abs(param))\n",
    "    return l1_reg\n",
    "    \n",
    "\n",
    "model = RNN(hidden_dim=2, device=device).to(device)\n",
    "\n",
    "\n",
    "### Training ###\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.0)\n",
    "steps = 3000\n",
    "log = 200\n",
    "lamb = 0e-4\n",
    "\n",
    "for step in range(steps):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pred_train = model(inputs_train)\n",
    "    loss_train = torch.mean((pred_train-labels_train)**2)\n",
    "    acc_train = 1-loss_train\n",
    "\n",
    "    pred_test = model(inputs_test)\n",
    "    loss_test = torch.mean((pred_test-labels_test)**2)\n",
    "    acc_test = 1-loss_test\n",
    "    \n",
    "    reg = l1(model)\n",
    "    loss = loss_train + lamb * reg\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % log == 0:\n",
    "        print(\"step = %d | train loss: %.2e | test loss %.2e | train acc: %.2e | test acc: %.2e | reg: %.2e \"%(step, loss_train.cpu().detach().numpy(), loss_test.cpu().detach().numpy(), acc_train.cpu().detach().numpy(), acc_test.cpu().detach().numpy(), reg.cpu().detach().numpy()))\n",
    "    \n",
    "torch.save(model.state_dict(), './model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
