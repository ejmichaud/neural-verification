{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20efca18-cb26-4a61-8451-a7c4b09a11d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from model import RNN\n",
    "\n",
    "### Preparation ####\n",
    "\n",
    "# set random seed\n",
    "seed = 3\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# set precision and device\n",
    "torch.set_default_dtype(torch.float)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device=\"cpu\"\n",
    "print(device)\n",
    "\n",
    "### load dataset ###\n",
    "\n",
    "\n",
    "def load_data(mode='train'):\n",
    "    data = np.loadtxt('./data_{}.txt'.format(mode), dtype='str')\n",
    "    inputs = data[:,:2]\n",
    "    labels = data[:,2]\n",
    "\n",
    "    def strs2mat(strings):\n",
    "        num = strings.shape[0]\n",
    "        mat = []\n",
    "        for i in range(num):\n",
    "            mat.append([*strings[i]])\n",
    "        return mat\n",
    "\n",
    "    inputs_ = np.transpose(np.array([strs2mat(inputs[:,0]), strs2mat(inputs[:,1])]), (1,2,0)).astype('float')\n",
    "    labels_ = np.array(strs2mat(labels))[:,:,np.newaxis].astype('float')\n",
    "\n",
    "    return inputs_, labels_\n",
    "\n",
    "inputs_train, labels_train = load_data(mode='train')\n",
    "inputs_test, labels_test = load_data(mode='test')\n",
    "\n",
    "inputs_train = torch.tensor(inputs_train, dtype=torch.float, requires_grad=True).to(device)\n",
    "labels_train = torch.tensor(labels_train, dtype=torch.float, requires_grad=True).to(device)\n",
    "inputs_test = torch.tensor(inputs_test, dtype=torch.float, requires_grad=True).to(device)\n",
    "labels_test = torch.tensor(labels_test, dtype=torch.float, requires_grad=True).to(device)\n",
    "\n",
    "def l1(model):\n",
    "    l1_reg = torch.tensor(0.).to(device)\n",
    "    for param in model.parameters():\n",
    "        l1_reg += torch.sum(torch.abs(param))\n",
    "    return l1_reg\n",
    "    \n",
    "\n",
    "model = RNN(hidden_dim=2, device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "777e3741-4601-436a-b4ca-19c3048e8075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0 | train loss: 2.45e+00 | test loss 2.40e+00 | train acc: -1.45e+00 | test acc: -1.40e+00 | reg: 6.06e+00 \n",
      "step = 200 | train loss: 2.36e-01 | test loss 2.38e-01 | train acc: 7.64e-01 | test acc: 7.62e-01 | reg: 7.36e+00 \n",
      "step = 400 | train loss: 2.09e-01 | test loss 2.13e-01 | train acc: 7.91e-01 | test acc: 7.87e-01 | reg: 9.69e+00 \n",
      "step = 600 | train loss: 1.83e-01 | test loss 1.88e-01 | train acc: 8.17e-01 | test acc: 8.12e-01 | reg: 1.23e+01 \n",
      "step = 800 | train loss: 1.72e-01 | test loss 1.77e-01 | train acc: 8.28e-01 | test acc: 8.23e-01 | reg: 1.42e+01 \n",
      "step = 1000 | train loss: 1.67e-01 | test loss 1.72e-01 | train acc: 8.33e-01 | test acc: 8.28e-01 | reg: 1.58e+01 \n",
      "step = 1200 | train loss: 1.29e-01 | test loss 1.33e-01 | train acc: 8.71e-01 | test acc: 8.67e-01 | reg: 1.93e+01 \n",
      "step = 1400 | train loss: 1.51e-02 | test loss 1.55e-02 | train acc: 9.85e-01 | test acc: 9.84e-01 | reg: 2.65e+01 \n",
      "step = 1600 | train loss: 7.66e-05 | test loss 7.81e-05 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 2.91e+01 \n",
      "step = 1800 | train loss: 9.72e-08 | test loss 9.89e-08 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 2.93e+01 \n",
      "step = 2000 | train loss: 3.97e-11 | test loss 4.03e-11 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 2.93e+01 \n",
      "step = 2200 | train loss: 1.26e-12 | test loss 1.29e-12 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 2.93e+01 \n",
      "step = 2400 | train loss: 1.09e-12 | test loss 1.12e-12 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 2.93e+01 \n",
      "step = 2600 | train loss: 7.60e-13 | test loss 7.83e-13 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 2.93e+01 \n",
      "step = 2800 | train loss: 6.24e-13 | test loss 6.41e-13 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 2.93e+01 \n"
     ]
    }
   ],
   "source": [
    "### Training ###\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.0)\n",
    "steps = 3000\n",
    "log = 200\n",
    "lamb = 0e-4\n",
    "\n",
    "for step in range(steps):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pred_train = model(inputs_train)\n",
    "    loss_train = torch.mean((pred_train-labels_train)**2)\n",
    "    acc_train = 1-loss_train\n",
    "\n",
    "    pred_test = model(inputs_test)\n",
    "    loss_test = torch.mean((pred_test-labels_test)**2)\n",
    "    acc_test = 1-loss_test\n",
    "    \n",
    "    reg = l1(model)\n",
    "    loss = loss_train + lamb * reg\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % log == 0:\n",
    "        print(\"step = %d | train loss: %.2e | test loss %.2e | train acc: %.2e | test acc: %.2e | reg: %.2e \"%(step, loss_train.cpu().detach().numpy(), loss_test.cpu().detach().numpy(), acc_train.cpu().detach().numpy(), acc_test.cpu().detach().numpy(), reg.cpu().detach().numpy()))\n",
    "    \n",
    "torch.save(model.state_dict(), './model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cc878d1-61c6-422a-9be0-cea37566d051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (Wh): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (Wx): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (Wy): Linear(in_features=2, out_features=1, bias=True)\n",
       "  (act): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41384b2d-fb8b-4194-948d-be8b5503e7ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs=inputs_train\n",
    "labels = labels_train\n",
    "seq_length=inputs_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59ce2df1-a53d-4c3b-9a27-491e7abd0cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = inputs.shape[0]\n",
    "hidden = torch.zeros(batch_size, model.hidden_dim).to(device)\n",
    "hiddens = []\n",
    "\n",
    "for i in range(seq_length):\n",
    "    hidden = model.act(model.Wh(hidden) + model.Wx(inputs[:,i,:]))\n",
    "    out = model.Wy(hidden)\n",
    "    hiddens.append(hidden.clone().cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e56a08e-37df-4066-8de6-6221ad452449",
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddens = np.transpose(np.array(hiddens), (1,0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c353b338-3805-4654-85d3-6316671e4272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(819, 1, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiddens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99b549d6-395a-46a4-92a0-04b279555d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc1eb0e8610>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAeTElEQVR4nO3df3TV9X348VdCIAFnYoUao2QRrSKVVTEckVDmmT/isR572FmPdKyiDs9pTtshMt1g7Ig6z8nsVrtahWoLurbgOFrpPKe0NX9UDGK3QcNOK2x0QksoQRY6k6hdKPDZH37Jt2lAcm9+vLnh8Tjn/sHHz4e8XidAnn7uzU1RlmVZAAAkUpx6AADg9CZGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgqZLUA/TH0aNHY9++fXHmmWdGUVFR6nEAgH7Isiy6urrivPPOi+LiE9//KIgY2bdvX1RXV6ceAwDIQ2tra0ycOPGE/70gYuTMM8+MiPeWKS8vTzwNANAfnZ2dUV1d3fN1/EQKIkaOPTVTXl4uRgCgwJzsJRZewAoAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgqYJ40zMAYPBdsOQ7fY797G9vHvY5cr4z8sorr8Qtt9wS5513XhQVFcW3v/3tk16zcePGqK2tjbKysrjwwgvjK1/5Sj6zAgCD5Hgh8n7Hh1LOMfLOO+/E5ZdfHo8//ni/zt+9e3d87GMfi9mzZ0dLS0v81V/9VSxcuDC+9a1v5TwsADBwJwuO4Q6SoizLsrwvLiqK9evXx5w5c054zl/+5V/Giy++GDt27Og51tDQEP/+7/8er732Wr8+TmdnZ1RUVERHR4efTQMAA5BLaAz0KZv+fv0e8hewvvbaa1FfX9/r2I033hhbtmyJX//618e9pru7Ozo7O3s9AICRachjZP/+/VFZWdnrWGVlZRw+fDja29uPe01jY2NUVFT0PKqrq4d6TAAgkWH51t7f/tHBx54ZOtGPFF66dGl0dHT0PFpbW4d8RgAgjSH/1t5zzz039u/f3+vYgQMHoqSkJMaPH3/ca0pLS6O0tHSoR2MEOVW+PQ2A3A35nZGZM2dGU1NTr2MvvfRSTJ8+PUaPHj3UH57TwKn07WkAp7r+/o/acP4PXc4x8vbbb8e2bdti27ZtEfHet+5u27Yt9uzZExHvPcUyf/78nvMbGhri5z//eSxevDh27NgRq1evjlWrVsW99947OBtwWjvVvj0NoBCcLDSG+85yzjGyZcuWmDZtWkybNi0iIhYvXhzTpk2L+++/PyIi2traesIkImLSpEmxYcOGePnll+OKK66Iv/mbv4nHHnss/uiP/miQVuB01d/QECQAfZ0oOFI8xT2g9xkZLt5nhN+Wa2B4/QjA8Dtl3mcEAOD9iBEAICkxAgAkJUYY8bxeBODUJkYoSKfi98kDkB8xQsE61b5PHoD8iBEK2qn0ffIA5GfIfzYNDDXhAVDY3BkBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSyitGVqxYEZMmTYqysrKora2N5ubm9z1/zZo1cfnll8e4ceOiqqoq7rzzzjh48GBeAwMAI0vOMbJu3bpYtGhRLFu2LFpaWmL27Nlx0003xZ49e457/qZNm2L+/PmxYMGCeP311+O5556Lf/u3f4u77rprwMMDAIUv5xh59NFHY8GCBXHXXXfFlClT4h/+4R+iuro6Vq5cedzzf/jDH8YFF1wQCxcujEmTJsVHP/rR+PSnPx1btmwZ8PAAQOHLKUYOHToUW7dujfr6+l7H6+vrY/Pmzce9pq6uLvbu3RsbNmyILMvizTffjOeffz5uvvnmE36c7u7u6Ozs7PUAAEamnGKkvb09jhw5EpWVlb2OV1ZWxv79+497TV1dXaxZsybmzp0bY8aMiXPPPTfOOuus+PKXv3zCj9PY2BgVFRU9j+rq6lzGBAAKSF4vYC0qKur16yzL+hw7Zvv27bFw4cK4//77Y+vWrfG9730vdu/eHQ0NDSf8/ZcuXRodHR09j9bW1nzGBAAKQEkuJ0+YMCFGjRrV5y7IgQMH+twtOaaxsTFmzZoV9913X0REfOQjH4kzzjgjZs+eHQ8//HBUVVX1uaa0tDRKS0tzGQ0AKFA53RkZM2ZM1NbWRlNTU6/jTU1NUVdXd9xr3n333Sgu7v1hRo0aFRHv3VEBAE5vOT9Ns3jx4vja174Wq1evjh07dsQ999wTe/bs6XnaZenSpTF//vye82+55ZZ44YUXYuXKlbFr16549dVXY+HChXHVVVfFeeedN3ibAAAFKaenaSIi5s6dGwcPHoyHHnoo2traYurUqbFhw4aoqamJiIi2trZe7zlyxx13RFdXVzz++OPx53/+53HWWWfFtddeG4888sjgbQEAFKyirACeK+ns7IyKioro6OiI8vLy1OMAAP3Q36/ffjYNAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkFReMbJixYqYNGlSlJWVRW1tbTQ3N7/v+d3d3bFs2bKoqamJ0tLSuOiii2L16tV5DQwAjCwluV6wbt26WLRoUaxYsSJmzZoVTz75ZNx0002xffv2+N3f/d3jXnPrrbfGm2++GatWrYoPfehDceDAgTh8+PCAhwcACl9RlmVZLhfMmDEjrrzyyli5cmXPsSlTpsScOXOisbGxz/nf+9734pOf/GTs2rUrzj777LyG7OzsjIqKiujo6Ijy8vK8fg8AYHj19+t3Tk/THDp0KLZu3Rr19fW9jtfX18fmzZuPe82LL74Y06dPj89//vNx/vnnxyWXXBL33ntv/OpXvzrhx+nu7o7Ozs5eDwBgZMrpaZr29vY4cuRIVFZW9jpeWVkZ+/fvP+41u3btik2bNkVZWVmsX78+2tvb4zOf+Uz88pe/POHrRhobG+PBBx/MZTQAoEDl9QLWoqKiXr/OsqzPsWOOHj0aRUVFsWbNmrjqqqviYx/7WDz66KPxzDPPnPDuyNKlS6Ojo6Pn0drams+YAEAByOnOyIQJE2LUqFF97oIcOHCgz92SY6qqquL888+PioqKnmNTpkyJLMti7969cfHFF/e5prS0NEpLS3MZDQAoUDndGRkzZkzU1tZGU1NTr+NNTU1RV1d33GtmzZoV+/bti7fffrvn2M6dO6O4uDgmTpyYx8gAwEiS89M0ixcvjq997WuxevXq2LFjR9xzzz2xZ8+eaGhoiIj3nmKZP39+z/nz5s2L8ePHx5133hnbt2+PV155Je6777740z/90xg7duzgbQIAFKSc32dk7ty5cfDgwXjooYeira0tpk6dGhs2bIiampqIiGhra4s9e/b0nP87v/M70dTUFH/2Z38W06dPj/Hjx8ett94aDz/88OBtAQAUrJzfZyQF7zMCAIVnSN5nBABgsIkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJ5RUjK1asiEmTJkVZWVnU1tZGc3Nzv6579dVXo6SkJK644op8PiwAMALlHCPr1q2LRYsWxbJly6KlpSVmz54dN910U+zZs+d9r+vo6Ij58+fHddddl/ewAMDIU5RlWZbLBTNmzIgrr7wyVq5c2XNsypQpMWfOnGhsbDzhdZ/85Cfj4osvjlGjRsW3v/3t2LZtW78/ZmdnZ1RUVERHR0eUl5fnMi4AkEh/v37ndGfk0KFDsXXr1qivr+91vL6+PjZv3nzC655++ul44403Yvny5f36ON3d3dHZ2dnrAQCMTDnFSHt7exw5ciQqKyt7Ha+srIz9+/cf95qf/vSnsWTJklizZk2UlJT06+M0NjZGRUVFz6O6ujqXMQGAApLXC1iLiop6/TrLsj7HIiKOHDkS8+bNiwcffDAuueSSfv/+S5cujY6Ojp5Ha2trPmMCAAWgf7cq/p8JEybEqFGj+twFOXDgQJ+7JRERXV1dsWXLlmhpaYnPfe5zERFx9OjRyLIsSkpK4qWXXoprr722z3WlpaVRWlqay2gAQIHK6c7ImDFjora2Npqamnodb2pqirq6uj7nl5eXx49//OPYtm1bz6OhoSEmT54c27ZtixkzZgxsegCg4OV0ZyQiYvHixXHbbbfF9OnTY+bMmfHUU0/Fnj17oqGhISLee4rlF7/4RXz961+P4uLimDp1aq/rzznnnCgrK+tzHAA4PeUcI3Pnzo2DBw/GQw89FG1tbTF16tTYsGFD1NTUREREW1vbSd9zBADgmJzfZyQF7zMCAIVnSN5nBABgsIkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJ5RUjK1asiEmTJkVZWVnU1tZGc3PzCc994YUX4oYbbogPfvCDUV5eHjNnzozvf//7eQ8MAIwsOcfIunXrYtGiRbFs2bJoaWmJ2bNnx0033RR79uw57vmvvPJK3HDDDbFhw4bYunVr/MEf/EHccsst0dLSMuDhAYDCV5RlWZbLBTNmzIgrr7wyVq5c2XNsypQpMWfOnGhsbOzX73HZZZfF3Llz4/777+/X+Z2dnVFRUREdHR1RXl6ey7gAQCL9/fqd052RQ4cOxdatW6O+vr7X8fr6+ti8eXO/fo+jR49GV1dXnH322Sc8p7u7Ozo7O3s9AICRKacYaW9vjyNHjkRlZWWv45WVlbF///5+/R5f+MIX4p133olbb731hOc0NjZGRUVFz6O6ujqXMQGAApLXC1iLiop6/TrLsj7HjufZZ5+NBx54INatWxfnnHPOCc9bunRpdHR09DxaW1vzGRMAKAAluZw8YcKEGDVqVJ+7IAcOHOhzt+S3rVu3LhYsWBDPPfdcXH/99e97bmlpaZSWluYyGgBQoHK6MzJmzJiora2NpqamXsebmpqirq7uhNc9++yzcccdd8TatWvj5ptvzm9SAGBEyunOSETE4sWL47bbbovp06fHzJkz46mnnoo9e/ZEQ0NDRLz3FMsvfvGL+PrXvx4R74XI/Pnz40tf+lJcffXVPXdVxo4dGxUVFYO4CgBQiHKOkblz58bBgwfjoYceira2tpg6dWps2LAhampqIiKira2t13uOPPnkk3H48OH47Gc/G5/97Gd7jt9+++3xzDPPDHwDAKCg5fw+Iyl4nxEAKDxD8j4jAACDTYwAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJFWSeoBULljynT7Hfva3NyeYBABOb6flnZHjhcj7HQcAhs5pFyMnCw5BAgDD67SKkf6GhiABgOFzWsUIAHDqESMAQFJiBABISowAAEmdVjHS3/cR8X4jADB8TqsYiTh5aAgRABhep12MRJw4OIQIAAy/0/bt4IUHAJwaTss7IwDAqUOMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEiqIN6BNcuyiIjo7OxMPAkA0F/Hvm4f+zp+IgURI11dXRERUV1dnXgSACBXXV1dUVFRccL/XpSdLFdOAUePHo19+/bFmWeeGUVFRSc9v7OzM6qrq6O1tTXKy8uHYcLhZ8fCN9L3i7DjSGHHkSHFjlmWRVdXV5x33nlRXHziV4YUxJ2R4uLimDhxYs7XlZeXj9g/VMfYsfCN9P0i7DhS2HFkGO4d3++OyDFewAoAJCVGAICkRmSMlJaWxvLly6O0tDT1KEPGjoVvpO8XYceRwo4jw6m8Y0G8gBUAGLlG5J0RAKBwiBEAICkxAgAkJUYAgKQKNkZWrFgRkyZNirKysqitrY3m5ub3PX/jxo1RW1sbZWVlceGFF8ZXvvKVYZo0f7ns2NbWFvPmzYvJkydHcXFxLFq0aPgGzVMu+73wwgtxww03xAc/+MEoLy+PmTNnxve///1hnDY/uey4adOmmDVrVowfPz7Gjh0bl156aXzxi18cxmnzk+vfxWNeffXVKCkpiSuuuGJoBxwEuez48ssvR1FRUZ/Hf/zHfwzjxLnL9fPY3d0dy5Yti5qamigtLY2LLrooVq9ePUzT5ieXHe+4447jfh4vu+yyYZw4N7l+DtesWROXX355jBs3LqqqquLOO++MgwcPDtO0vyUrQP/0T/+UjR49OvvqV7+abd++Pbv77ruzM844I/v5z39+3PN37dqVjRs3Lrv77ruz7du3Z1/96lez0aNHZ88///wwT95/ue64e/fubOHChdk//uM/ZldccUV29913D+/AOcp1v7vvvjt75JFHsn/913/Ndu7cmS1dujQbPXp09qMf/WiYJ++/XHf80Y9+lK1duzb7yU9+ku3evTv7xje+kY0bNy578sknh3ny/st1x2Peeuut7MILL8zq6+uzyy+/fHiGzVOuO/7gBz/IIiL7z//8z6ytra3ncfjw4WGevP/y+Tx+/OMfz2bMmJE1NTVlu3fvzv7lX/4le/XVV4dx6tzkuuNbb73V6/PX2tqanX322dny5cuHd/B+ynW/5ubmrLi4OPvSl76U7dq1K2tubs4uu+yybM6cOcM8+XsKMkauuuqqrKGhodexSy+9NFuyZMlxz/+Lv/iL7NJLL+117NOf/nR29dVXD9mMA5Xrjr/pmmuuOeVjZCD7HfPhD384e/DBBwd7tEEzGDv+4R/+YfapT31qsEcbNPnuOHfu3Oyv//qvs+XLl5/yMZLrjsdi5H/+53+GYbrBkeuO3/3ud7OKiors4MGDwzHeoBjo38f169dnRUVF2c9+9rOhGG/Act3v7/7u77ILL7yw17HHHnssmzhx4pDN+H4K7mmaQ4cOxdatW6O+vr7X8fr6+ti8efNxr3nttdf6nH/jjTfGli1b4te//vWQzZqvfHYsJIOx39GjR6OrqyvOPvvsoRhxwAZjx5aWlti8eXNcc801QzHigOW749NPPx1vvPFGLF++fKhHHLCBfB6nTZsWVVVVcd1118UPfvCDoRxzQPLZ8cUXX4zp06fH5z//+Tj//PPjkksuiXvvvTd+9atfDcfIORuMv4+rVq2K66+/PmpqaoZixAHJZ7+6urrYu3dvbNiwIbIsizfffDOef/75uPnmm4dj5D4K4gfl/ab29vY4cuRIVFZW9jpeWVkZ+/fvP+41+/fvP+75hw8fjvb29qiqqhqyefORz46FZDD2+8IXvhDvvPNO3HrrrUMx4oANZMeJEyfGf//3f8fhw4fjgQceiLvuumsoR81bPjv+9Kc/jSVLlkRzc3OUlJz6//zks2NVVVU89dRTUVtbG93d3fGNb3wjrrvuunj55Zfj93//94dj7Jzks+OuXbti06ZNUVZWFuvXr4/29vb4zGc+E7/85S9PydeNDPTfnLa2tvjud78ba9euHaoRBySf/erq6mLNmjUxd+7c+N///d84fPhwfPzjH48vf/nLwzFyH6f+vwYnUFRU1OvXWZb1OXay8493/FSS646FJt/9nn322XjggQfin//5n+Occ84ZqvEGRT47Njc3x9tvvx0//OEPY8mSJfGhD30o/viP/3goxxyQ/u545MiRmDdvXjz44INxySWXDNd4gyKXz+PkyZNj8uTJPb+eOXNmtLa2xt///d+fkjFyTC47Hj16NIqKimLNmjU9P5H10UcfjU984hPxxBNPxNixY4d83nzk+2/OM888E2eddVbMmTNniCYbHLnst3379li4cGHcf//9ceONN0ZbW1vcd9990dDQEKtWrRqOcXspuBiZMGFCjBo1qk/tHThwoE8VHnPuuece9/ySkpIYP378kM2ar3x2LCQD2W/dunWxYMGCeO655+L6668fyjEHZCA7Tpo0KSIifu/3fi/efPPNeOCBB07JGMl1x66urtiyZUu0tLTE5z73uYh474talmVRUlISL730Ulx77bXDMnt/Ddbfxauvvjq++c1vDvZ4gyKfHauqquL888/v9aPhp0yZElmWxd69e+Piiy8e0plzNZDPY5ZlsXr16rjttttizJgxQzlm3vLZr7GxMWbNmhX33XdfRER85CMfiTPOOCNmz54dDz/88LA/Y1BwrxkZM2ZM1NbWRlNTU6/jTU1NUVdXd9xrZs6c2ef8l156KaZPnx6jR48eslnzlc+OhSTf/Z599tm44447Yu3atcme1+yvwfocZlkW3d3dgz3eoMh1x/Ly8vjxj38c27Zt63k0NDTE5MmTY9u2bTFjxozhGr3fBuvz2NLScso9HXxMPjvOmjUr9u3bF2+//XbPsZ07d0ZxcXFMnDhxSOfNx0A+jxs3boz/+q//igULFgzliAOSz37vvvtuFBf3ToBRo0ZFxP9/5mBYDf9rZgfu2LcwrVq1Ktu+fXu2aNGi7Iwzzuh5lfOSJUuy2267ref8Y9/ae88992Tbt2/PVq1aVTDf2tvfHbMsy1paWrKWlpastrY2mzdvXtbS0pK9/vrrKcY/qVz3W7t2bVZSUpI98cQTvb7d7q233kq1wknluuPjjz+evfjii9nOnTuznTt3ZqtXr87Ky8uzZcuWpVrhpPL5c/qbCuG7aXLd8Ytf/GK2fv36bOfOndlPfvKTbMmSJVlEZN/61rdSrXBSue7Y1dWVTZw4MfvEJz6Rvf7669nGjRuziy++OLvrrrtSrXBS+f5Z/dSnPpXNmDFjuMfNWa77Pf3001lJSUm2YsWK7I033sg2bdqUTZ8+PbvqqquSzF+QMZJlWfbEE09kNTU12ZgxY7Irr7wy27hxY89/u/3227Nrrrmm1/kvv/xyNm3atGzMmDHZBRdckK1cuXKYJ85drjtGRJ9HTU3N8A6dg1z2u+aaa4673+233z78g+cglx0fe+yx7LLLLsvGjRuXlZeXZ9OmTctWrFiRHTlyJMHk/Zfrn9PfVAgxkmW57fjII49kF110UVZWVpZ94AMfyD760Y9m3/nOdxJMnZtcP487duzIrr/++mzs2LHZxIkTs8WLF2fvvvvuME+dm1x3fOutt7KxY8dmTz311DBPmp9c93vssceyD3/4w9nYsWOzqqqq7E/+5E+yvXv3DvPU7ynKshT3YwAA3lNwrxkBAEYWMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJDU/wHcASHvThd4OgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "\n",
    "x = hiddens[:,:,0].reshape(-1,)\n",
    "y = hiddens[:,:,1].reshape(-1,)\n",
    "\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15aff584-1b54-49aa-993e-db451ca998eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "X = np.transpose(np.array([x,y]))\n",
    "kmeans = KMeans(n_clusters=4, random_state=0, n_init=\"auto\").fit(X)\n",
    "vectorlist = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fac2fa2-0c97-4298-86ed-9310c82298a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8116605 , 0.9999591 ],\n",
       "       [0.01835859, 0.11368805],\n",
       "       [0.2225262 , 0.9839434 ],\n",
       "       [0.21972343, 0.98081225]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36a945cf-653b-4b3b-85ff-4fc55a30bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find parallelogram\n",
    "\n",
    "# Tries to interpret 2^n vectors as n bits, defining an n-dimensional parallelogram\n",
    "# Max Tegmark Aug 25 2023\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy, itertools\n",
    "\n",
    "\n",
    "def bitstring2int(s): return int(s,2)\n",
    "\n",
    "def int2bitstring(n,i): \n",
    "    s = bin(i)[2:]\n",
    "    return \"\".join([\"0\" for j in range(n-len(s))])+s\n",
    "\n",
    "def str2int(lst): return list(map(int,lst))\n",
    "\n",
    "# Computes all 2^n bitstrings f length n:\n",
    "def allstrings(n): [int2bitstring(n,i) for i in range(2**n)]\n",
    "\n",
    "# Computes B-matrix whose rows are all 2^n bit strings of length n:\n",
    "def Bmatrix(n): \n",
    "    return np.array([str2int(list(int2bitstring(n,i))) for i in range(2**n)])\n",
    "\n",
    "def list2nN(lst):\n",
    "    N = len(lst)\n",
    "    n = int(np.log(N)/np.log(2))\n",
    "    if 2**n != N: \n",
    "        print(\"List length not power of 2: \",f,N,n)\n",
    "        exit()\n",
    "    return n,N                \n",
    "\n",
    "# Input:   a list of 2^n vectors\n",
    "# Output:  fitting error to model where these vectors form an n-dimensional parallelogram in canonical order\n",
    "# Demo:  vectorlist =[[10,20],[10,22],[11,21],[11,23]]\n",
    "def parallelogramFit(vectorlist):\n",
    "    n,N = list2nN(vectorlist)\n",
    "    A = np.array(vectorlist)\n",
    "    A = A - A[0] # WLOG 1st point is at the origin\n",
    "    B = Bmatrix(n)\n",
    "    BtB = B.T @ B\n",
    "    BBinv = np.linalg.inv(BtB)\n",
    "    X = BBinv @ B.T @ A\n",
    "    E = A - B @ X # Fitting error\n",
    "    error = np.trace(E.T @ E)/np.trace(A.T @ A) # Between & 1, where 0 = perfect\n",
    "    return error\n",
    "\n",
    "\n",
    "# Input:   a list of 2^n vectors\n",
    "# Output:  a list of 2^b bitstring of length n, labeling these vectors\n",
    "# Demo:  vectorlist =[[10,20],[10,22],[11,21],[11,23]]\n",
    "# Calls parallelogramFit for all permutations of the vectors and returns best fit.\n",
    "\n",
    "# Computes inverse permutation:\n",
    "def invperm(perm):\n",
    "    n = len(perm)\n",
    "    p = [0 for i in range(n)]\n",
    "    for i in range(n): p[perm[i]]=i\n",
    "    return p\n",
    "# Demo: invperm([1,2,3,0])\n",
    "\n",
    "def vecs2bits(vectorlist):\n",
    "    n,N = list2nN(vectorlist)\n",
    "    perms = list(itertools.permutations(range(N)))\n",
    "    besterror = 666.\n",
    "    for perm in itertools.permutations(range(N)):\n",
    "        A = [vectorlist[i] for i in perm]\n",
    "        error = parallelogramFit(A)\n",
    "        #print(perm,error)\n",
    "        if error < besterror:\n",
    "            error = besterror\n",
    "            bestperm = perm\n",
    "    B = Bmatrix(n)\n",
    "    p = invperm(bestperm)\n",
    "    bestB = np.array([B[p[i]] for i in range(N)]).astype(int)\n",
    "    return bestB,besterror\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0549d5b3-870a-443e-9cb5-07cc04dc07df",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_bits = 1 - vecs2bits(vectorlist.tolist())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcae2574-a7a1-4bc2-8b30-3a05f7f60f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(2**4)\n",
    "\n",
    "rs = []\n",
    "\n",
    "for i in range(4):\n",
    "    x, r = np.divmod(x, 2)\n",
    "    rs.append(r)\n",
    "    \n",
    "rs = np.transpose(np.array(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d379a6a6-3dce-4a57-8ff3-a7b43b090840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [1, 1, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [1, 0, 1, 0],\n",
       "       [0, 1, 1, 0],\n",
       "       [1, 1, 1, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [1, 0, 0, 1],\n",
       "       [0, 1, 0, 1],\n",
       "       [1, 1, 0, 1],\n",
       "       [0, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [0, 1, 1, 1],\n",
       "       [1, 1, 1, 1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6970f827-0005-4ffa-b823-eee1d669517e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2cf372a-6b3f-4873-9def-21a5a3032af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8116605 , 0.9999591 ],\n",
       "       [0.01835859, 0.11368805],\n",
       "       [0.2225262 , 0.9839434 ],\n",
       "       [0.21972343, 0.98081225]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f938824c-9178-461c-a9a8-d395ca91679c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8116605  0.9999591 ]\n",
      " [0.2225262  0.9839434 ]\n",
      " [0.01835859 0.11368805]\n",
      " [0.21972343 0.98081225]\n",
      " [0.8116605  0.9999591 ]\n",
      " [0.2225262  0.9839434 ]\n",
      " [0.01835859 0.11368805]\n",
      " [0.21972343 0.98081225]\n",
      " [0.8116605  0.9999591 ]\n",
      " [0.2225262  0.9839434 ]\n",
      " [0.01835859 0.11368805]\n",
      " [0.21972343 0.98081225]\n",
      " [0.8116605  0.9999591 ]\n",
      " [0.2225262  0.9839434 ]\n",
      " [0.01835859 0.11368805]\n",
      " [0.21972343 0.98081225]]\n",
      "[[0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]]\n",
      "torch.Size([16, 2])\n"
     ]
    }
   ],
   "source": [
    "hidden = vectorlist[rs[:,0]*2 + rs[:,1]]\n",
    "print(hidden)\n",
    "x = rs[:,[2,3]]\n",
    "print(x)\n",
    "\n",
    "hidden = torch.tensor(hidden, dtype=torch.float)\n",
    "x = torch.tensor(x, dtype=torch.float)\n",
    "print(x.shape)\n",
    "out = model.Wy(hidden)\n",
    "\n",
    "hidden = model.act(model.Wh(hidden) + model.Wx(x))\n",
    "\n",
    "out_bit = np.round(out[:,0].detach().numpy()).astype(int)\n",
    "\n",
    "hidden_next_bit = cluster_bits[np.argmin(np.linalg.norm(hidden.detach().numpy()[np.newaxis,:,:] - vectorlist[:,np.newaxis,:], axis=2), axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88d3f444-d915-48fb-bda0-08de4c358819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "365c5dc0-7d1d-4034-8ce0-da3d5b8e4043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (hidden_current, x_current) => hidden_next; rs => hidden_next_bit\n",
    "# hidden_current = rs[:4, :2] => out_bit = out_bit[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "495a65f6-38e5-48c7-b856-979ee9cd9120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# three symbolic functions to be learned\n",
    "# out from h[0], h[1]\n",
    "# h[0] from last h[0], h[1], current x[0], x[1]\n",
    "# h[1] from last h[0], h[1], current x[0], x[1]\n",
    "\n",
    "\n",
    "# Tools for symbolic regression of boolean functions\n",
    "# Max Tegmark Aug 24-25 2023\n",
    "\n",
    "import time\n",
    "from math import log\n",
    "\n",
    "def bitstring2int(s): return int(s,2)\n",
    "\n",
    "def int2bitstring(n,i): \n",
    "    s = bin(i)[2:]\n",
    "    return \"\".join([\"0\" for j in range(n-len(s))])+s\n",
    "\n",
    "# A boolean function f is defined as a string f of length 2^n, say \"00010001\"\n",
    "# The argument list is defined as a string x length n ,say \"011\"\n",
    "# Returns char \"0\" or \"1\"\n",
    "def booleval(f,x):\n",
    "    n = len(x)\n",
    "    if len(f) != 2**n: \n",
    "        print(\"String length mismatch error: \",n,2**n,len(s))\n",
    "        exit()\n",
    "    i = bitstring2int(x)\n",
    "    return f[i]\n",
    "# DEMO: booleval(\"11111111\",\"111\")\n",
    "\n",
    "# Flip the ith bit in the bitstring n\n",
    "def flip_bit(x,i):\n",
    "    s = list(x)\n",
    "    s[i] = str(1-int(s[i]))\n",
    "    return \"\".join(s)\n",
    "# DEMO: flip_bit(\"11111111\",2)\n",
    "\n",
    "def f2nN(f):\n",
    "    N = len(f)\n",
    "    n = int(log(N)/log(2))\n",
    "    if 2**n != N: \n",
    "        print(\"String length not power of 2: \",f,N,n)\n",
    "        exit()\n",
    "    return n,N\n",
    "\n",
    "def bitsum(s): return sum([int(c) for c in s])\n",
    "\n",
    "def find_variables_used(f):\n",
    "    # Returns e.g. \"101\" if function f depends on x_0 & x_2 but not x_1\n",
    "    n,N = f2nN(f)\n",
    "    s = [\"0\" for i in range(n)]\n",
    "    for i in range(N):\n",
    "        x = int2bitstring(n,i)\n",
    "        for k in range(n):\n",
    "            if booleval(f,x) != booleval(f,flip_bit(x,k)): s[k] = \"1\"\n",
    "    return \"\".join(s)\n",
    "# DEMO: find_variables_used(\"01100110\") # x[1] XOR x[2]\n",
    "\n",
    "# Return the function f restricted to the only variables it depends on:\n",
    "def subfunc(f):\n",
    "    used = find_variables_used(f)\n",
    "    n = len(used)\n",
    "    vars = [i for i in range(n) if used[i]==\"1\"]\n",
    "    n1 = len(vars)\n",
    "    N1 = 2**n1\n",
    "    f1 = [\"0\" for i in range(N1)]\n",
    "    for i in range(N1):\n",
    "        x1 = int2bitstring(n1,i)\n",
    "        x  = [\"0\" for i in range(n)]\n",
    "        for k in range(n1): x[vars[k]] = x1[k]\n",
    "        f1[i] = booleval(f,\"\".join(x))\n",
    "    return f1,vars\n",
    "# DEMO: subfunc(\"01100110\") # x[1] XOR x[2]\n",
    "\n",
    "def parallelogram():\n",
    "    return\n",
    "\n",
    "def symmetricQ(f):\n",
    "    # Check if f is fully symmetric under all permutations of its variables, thus depending only on variable sum\n",
    "    # If so, returns string giving value taken for each bit sum, otherwise returns \"\".\n",
    "    # 2**(n+1) out of the 2**N functions are symmetric.\n",
    "    n,N = f2nN(f)\n",
    "    s = [\"-\" for i in range(n+1)]\n",
    "    for i in range(N):\n",
    "        x = int2bitstring(n,i)\n",
    "        k = bitsum(x)\n",
    "        c = booleval(f,x) \n",
    "        if s[k] != c:\n",
    "            if s[k] == \"-\": s[k] = c\n",
    "            else: return \"\"\n",
    "    return \"\".join(s)\n",
    "\n",
    "# Write x as boolean condition\"\n",
    "def x2dnf(x,varnames):\n",
    "    n = len(x)\n",
    "    return \" and \".join([[\"not \",\"\"][int(x[i])]+varnames[i] for i in range(n)])\n",
    "# Demo: x2dnf(\"110\",\"abc\") \n",
    "# returns \"a and b and not c\"\n",
    "\n",
    "# Write f in disjunctive normal form:\n",
    "def f2dnf(f,varnames):\n",
    "    n,N = f2nN(f)\n",
    "    return \" or \".join([\"(\"+x2dnf(int2bitstring(n,i),varnames)+\")\" for i in range(N) if f[i]==\"1\"])\n",
    "# Demo: f2dnf(\"01100110\",\"abc\") \n",
    "# returns \"a and b and not c\"\n",
    "\n",
    "# Checks if string of type \"010101010\":\n",
    "def parityQ(s):\n",
    "    x = [int(c) for c in s]\n",
    "    if x[0] != 0: return False\n",
    "    for i in range(len(x)-1):\n",
    "        if x[i]+x[i+1] != 1: return False\n",
    "    return True\n",
    "# DEMO: parityQ(\"01010\")\n",
    "    \n",
    "# Checks if string is sorted, like e.g. \"0000111\":\n",
    "def sortedQ(s):\n",
    "    for i in range(len(s)-1):\n",
    "        if s[i]>s[i+1]: return False\n",
    "    return True\n",
    "\n",
    "# Returns 4 if s=\"0000111\", returns -1 if not step function\n",
    "def stepupQ(s):\n",
    "    if not sortedQ(s): return -1\n",
    "    for i in range(len(s)): \n",
    "        if s[i]==\"1\": return i-1\n",
    "    return -1\n",
    "\n",
    "# Returns 4 if s=\"1111000\", returns -1 if not step function\n",
    "def stepdownQ(s):\n",
    "    if not sortedQ(\"\".join(reversed(s))): return -1\n",
    "    for i in range(len(s)): \n",
    "        if s[i]==\"0\": return i-1\n",
    "    return -1\n",
    "\n",
    "def symmfunc(s,varsum):\n",
    "    return \" or \".join([varsum+\"==\"+str(i) for i in range(len(s)) if s[i]==\"1\"])\n",
    "# Demo: symmfunc(\"1001\",\"abc\") \n",
    "# returns \"a+b+c==0 or a+b+c==3\"\n",
    "\n",
    "# Given a string s specifying how function depends on bit sum, return the formula:\n",
    "def symmetric_formula(s,varnames):\n",
    "    if len(varnames)==1 and s==\"10\": return \"not \"+varnames[0]\n",
    "    if parityQ(s): return \" xor \".join(varnames) # f is xor of all variables\n",
    "    varsum = \"+\".join(varnames)\n",
    "    i = stepupQ(s) \n",
    "    if i >= 0: return varsum+\">\"+str(i)\n",
    "    i = stepdownQ(s) \n",
    "    if i >= 0: return varsum+\"<\"+str(i+1)\n",
    "    return symmfunc(s,varsum)\n",
    "\n",
    "def formula(f):\n",
    "    f1,vars = subfunc(f)\n",
    "    varnames = [chr(97+i) for i in vars]\n",
    "    if varnames == []: return str(bool(int(f[0]))) # Function is a constant\n",
    "    formula1 = f2dnf(f1,varnames)\n",
    "    s = symmetricQ(f1)\n",
    "    if s == \"\": return formula1\n",
    "    formula2 = symmetric_formula(s,varnames)\n",
    "    if len(formula2)<len(formula1): formula1 = formula2 # Pick shortest formula\n",
    "    return formula1\n",
    "\n",
    "\n",
    "#def shortest_formula(f):\n",
    "    \n",
    "\n",
    "def demo1():\n",
    "    n = 3\n",
    "    N = 2**n\n",
    "    for i in range(2**N):\n",
    "        f = int2bitstring(N,i)\n",
    "        print(f+\": \"+formula(f))\n",
    "        #time.sleep(.5)\n",
    "    return\n",
    "\n",
    "def demo2():\n",
    "    print(formula(\"00000000\")) # False\n",
    "    print(formula(\"11111111\")) # True\n",
    "    print(formula(\"00001111\")) # a\n",
    "    print(formula(\"01100110\")) # b xor c\n",
    "    print(formula(\"01101001\")) # a xor b xor c\n",
    "    print(formula(\"01111111\")) # a+b+c==1 or a+b+c==2 or a+b+c==3 <=========\n",
    "    print(formula(\"00010111\")) # a+b+c==2 or a+b+c==3\n",
    "    print(formula(\"00000001\")) # a+b+c==3\n",
    "    print(formula(\"11101000\")) # a+b+c==0 or a+b+c==1  FAILS\n",
    "    print(formula(\"10000001\")) # a+b+c==0 or a+b+c==3\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d3ba085-5fbb-467d-9a2a-c2740825a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (hidden_current, x_current) => hidden_next; rs => hidden_next_bit\n",
    "# hidden_current = rs[:4, :2] => out_bit = out_bit[:4]\n",
    "str_arr = np.zeros(16,dtype=int)\n",
    "indices = np.sum(rs * 2**np.array([3,2,1,0]), axis=1)\n",
    "str_arr[indices] = hidden_next_bit[:,0]\n",
    "string = \"\"\n",
    "for bit in list(str_arr):\n",
    "    string += str(bit)\n",
    "next_a_formula = formula(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7543cab3-4a22-4de9-b182-70d22c1dd0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c xor d'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_a_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3402df4a-b597-4607-b7fb-f552482b6e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_arr = np.zeros(16,dtype=int)\n",
    "indices = np.sum(rs * 2**np.array([3,2,1,0]), axis=1)\n",
    "str_arr[indices] = hidden_next_bit[:,1]\n",
    "string = \"\"\n",
    "for bit in list(str_arr):\n",
    "    string += str(bit)\n",
    "next_b_formula = formula(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa640887-269a-4637-88de-da744abbd513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c+d<2'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_b_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "996a04fe-2770-47b3-bb17-8f703139f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output bit\n",
    "str_arr = np.zeros(4,dtype=int)\n",
    "indices = np.sum(rs[:4,:2] * 2**np.array([1,0]), axis=1)\n",
    "str_arr[indices] = out_bit[:4]\n",
    "string = \"\"\n",
    "for bit in list(str_arr):\n",
    "    string += str(bit)\n",
    "out_formula = formula(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6642d052-e4dc-462c-8d97-f9f55b4e3598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "265c1ef0-3512-4a50-b9d9-d1698eba00db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c xor d\n",
      "c+d<2\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "print(next_a_formula)\n",
    "print(next_b_formula)\n",
    "print(out_formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2bb99e0a-8231-4793-8d27-b968ab0a458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "#This is Vedang's version of the code to go from text to python\n",
    "def convert_logical_to_python(logical_expression):\n",
    "    \"\"\"\n",
    "    Converts a logical expression into its equivalent Python representation using NumPy bitwise operators.\n",
    "\n",
    "    Args:\n",
    "        logical_expression (str): The logical expression to be converted.\n",
    "\n",
    "    Returns:\n",
    "        str: The Python representation of the logical expression.\n",
    "    \"\"\"\n",
    "    \n",
    "    #This is the case we have a constraint\n",
    "    if \"<\" in logical_expression or \">\" in logical_expression:\n",
    "        return logical_expression\n",
    "    \n",
    "    def extract_elements(logical_expression):\n",
    "        \"\"\"\n",
    "        Extracts elements enclosed in parentheses from a logical expression.\n",
    "\n",
    "        Args:\n",
    "            logical_expression (str): The logical expression.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of elements inside parentheses.\n",
    "        \"\"\"\n",
    "        inside_elements = re.findall(r'\\((.*?)\\)', logical_expression)\n",
    "        return inside_elements\n",
    "\n",
    "    def apply_not(expression):\n",
    "        \"\"\"\n",
    "        Applies the NOT operation to a given expression.\n",
    "\n",
    "        Args:\n",
    "            expression (str): The expression to be negated.\n",
    "\n",
    "        Returns:\n",
    "            str: The negated expression.\n",
    "        \"\"\"\n",
    "        return f'1 - {expression}'\n",
    "\n",
    "    def convert_logic_operators(formula_split):\n",
    "        \"\"\"\n",
    "        Converts logical operators in a formula split into their equivalent Python representation.\n",
    "\n",
    "        Args:\n",
    "            formula_split (list): The split components of a logical formula.\n",
    "\n",
    "        Returns:\n",
    "            list: The list of converted components.\n",
    "        \"\"\"\n",
    "\n",
    "        operators_mapping = {'or': 'np.bitwise_or', 'and': 'np.bitwise_and', 'xor': 'np.bitwise_xor', 'not': apply_not}\n",
    "\n",
    "        formula_np = []\n",
    "        skip_next = False\n",
    "\n",
    "        for i, sub in enumerate(formula_split):\n",
    "            if skip_next:\n",
    "                skip_next = False\n",
    "                continue\n",
    "\n",
    "            mapped_sub = operators_mapping.get(sub, sub)\n",
    "            if callable(mapped_sub):\n",
    "                mapped_sub = mapped_sub(formula_split[i + 1])\n",
    "                skip_next = True\n",
    "\n",
    "            formula_np.append(mapped_sub)\n",
    "        return formula_np\n",
    "\n",
    "    def build_expression(formula_np):\n",
    "        \"\"\"\n",
    "        Builds a Python expression from a list of converted components.\n",
    "\n",
    "        Args:\n",
    "            formula_np (list): The list of converted components.\n",
    "\n",
    "        Returns:\n",
    "            str: The Python expression.\n",
    "        \"\"\"\n",
    "\n",
    "        expression_str = \"\"\n",
    "        i = 0\n",
    "\n",
    "        while i < len(formula_np):\n",
    "            sub = formula_np[i]\n",
    "\n",
    "            if sub in {'np.bitwise_and', 'np.bitwise_or', 'np.bitwise_xor'}:\n",
    "                expression_str = f'{sub}({expression_str},{formula_np[i+1]})'\n",
    "                i += 2\n",
    "            elif callable(sub):\n",
    "                expression_str = f'{sub}({formula_np[i+1]})'\n",
    "                i += 2\n",
    "            else:\n",
    "                expression_str += sub\n",
    "                i += 1\n",
    "\n",
    "        return expression_str\n",
    "\n",
    "    inside_elements = extract_elements(logical_expression)\n",
    "    to_or = [build_expression(convert_logic_operators(element.split())) for element in inside_elements]\n",
    "    \n",
    "    #If there are no subexpressions in () - we don't have to OR all of them ()\n",
    "    if len(inside_elements) == 0:\n",
    "        return build_expression(convert_logic_operators(logical_expression.split()))\n",
    "\n",
    "    def or_everything(expressions):\n",
    "        \"\"\"\n",
    "        Combines multiple expressions using the NumPy bitwise OR operation.\n",
    "\n",
    "        Args:\n",
    "            expressions (list): List of expressions to be combined.\n",
    "\n",
    "        Returns:\n",
    "            str: The final combined expression.\n",
    "        \"\"\"\n",
    "        if len(expressions) < 2:\n",
    "            return expressions[0]\n",
    "\n",
    "        final_expr = f\"np.bitwise_or({expressions[0]}, {expressions[1]})\"\n",
    "        for i in range(2, len(expressions)):\n",
    "            final_expr = f\"np.bitwise_or({final_expr}, {expressions[i]})\"\n",
    "        return final_expr\n",
    "    return or_everything(to_or)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47358cf9-6907-430d-b41a-b032a7c724d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_a_formula_str = convert_logical_to_python(next_a_formula)\n",
    "next_b_formula_str = convert_logical_to_python(next_b_formula)\n",
    "out_formula_str = convert_logical_to_python(out_formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7440da37-e0fa-434a-89ea-9c15c040883f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.bitwise_xor(c,d)\n",
      "c+d<2\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "print(next_a_formula_str)\n",
    "print(next_b_formula_str)\n",
    "print(out_formula_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94336ba0-9a3e-4efc-8ac7-a6a98a173318",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = inputs.detach().numpy().astype(int)\n",
    "out_labels = labels.detach().numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06871d25-e9ca-4c14-8c8d-538ec10dce21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xs are inputs, with shape (batch size, sequence length, 2)\n",
    "a = np.zeros(xs.shape[0],).astype(int)\n",
    "b = np.zeros(xs.shape[0],).astype(int)\n",
    "outs = []\n",
    "\n",
    "for i in range(xs.shape[1]):\n",
    "    c = xs[:,i,0]\n",
    "    d = xs[:,i,1]\n",
    "\n",
    "    exec('a = ' + next_a_formula_str)\n",
    "    exec('b = ' + next_b_formula_str)\n",
    "    exec('out = ' + out_formula_str)\n",
    "    outs.append(a)\n",
    "\n",
    "outs = np.transpose(np.array(outs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84cec756-552f-4e20-905a-70821e9204a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hack/Error\n",
    "#This is supposed to be 1-out_labels[:,:,0] but somehow that isnt working\n",
    "num_error = np.sum((1-out_labels[:,:,0] == outs))\n",
    "num_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491d8b4d-188c-45ff-b32a-c0fe769079b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
