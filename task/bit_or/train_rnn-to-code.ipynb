{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20efca18-cb26-4a61-8451-a7c4b09a11d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from model import RNN\n",
    "\n",
    "### Preparation ####\n",
    "\n",
    "# set random seed\n",
    "seed = 4\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# set precision and device\n",
    "torch.set_default_dtype(torch.float)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "### load dataset ###\n",
    "\n",
    "\n",
    "def load_data(mode='train'):\n",
    "    data = np.loadtxt('./data_{}.txt'.format(mode), dtype='str')\n",
    "    inputs = data[:,:2]\n",
    "    labels = data[:,2]\n",
    "\n",
    "    def strs2mat(strings):\n",
    "        num = strings.shape[0]\n",
    "        mat = []\n",
    "        for i in range(num):\n",
    "            mat.append([*strings[i]])\n",
    "        return mat\n",
    "\n",
    "    inputs_ = np.transpose(np.array([strs2mat(inputs[:,0]), strs2mat(inputs[:,1])]), (1,2,0)).astype('float')\n",
    "    labels_ = np.array(strs2mat(labels))[:,:,np.newaxis].astype('float')\n",
    "\n",
    "    return inputs_, labels_\n",
    "\n",
    "inputs_train, labels_train = load_data(mode='train')\n",
    "inputs_test, labels_test = load_data(mode='test')\n",
    "\n",
    "inputs_train = torch.tensor(inputs_train, dtype=torch.float, requires_grad=True).to(device)\n",
    "labels_train = torch.tensor(labels_train, dtype=torch.float, requires_grad=True).to(device)\n",
    "inputs_test = torch.tensor(inputs_test, dtype=torch.float, requires_grad=True).to(device)\n",
    "labels_test = torch.tensor(labels_test, dtype=torch.float, requires_grad=True).to(device)\n",
    "\n",
    "def l1(model):\n",
    "    l1_reg = torch.tensor(0.).to(device)\n",
    "    for param in model.parameters():\n",
    "        l1_reg += torch.sum(torch.abs(param))\n",
    "    return l1_reg\n",
    "    \n",
    "\n",
    "model = RNN(hidden_dim=2, device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "777e3741-4601-436a-b4ca-19c3048e8075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0 | train loss: 2.87e-01 | test loss 2.94e-01 | train acc: 7.13e-01 | test acc: 7.06e-01 | reg: 6.06e+00 \n",
      "step = 200 | train loss: 2.55e-02 | test loss 2.51e-02 | train acc: 9.75e-01 | test acc: 9.75e-01 | reg: 1.30e+01 \n",
      "step = 400 | train loss: 3.95e-03 | test loss 4.33e-03 | train acc: 9.96e-01 | test acc: 9.96e-01 | reg: 1.66e+01 \n",
      "step = 600 | train loss: 1.52e-03 | test loss 1.70e-03 | train acc: 9.98e-01 | test acc: 9.98e-01 | reg: 1.82e+01 \n",
      "step = 800 | train loss: 8.17e-04 | test loss 9.18e-04 | train acc: 9.99e-01 | test acc: 9.99e-01 | reg: 1.91e+01 \n",
      "step = 1000 | train loss: 5.10e-04 | test loss 5.75e-04 | train acc: 9.99e-01 | test acc: 9.99e-01 | reg: 1.97e+01 \n",
      "step = 1200 | train loss: 3.48e-04 | test loss 3.93e-04 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 2.03e+01 \n",
      "step = 1400 | train loss: 2.50e-04 | test loss 2.83e-04 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 2.07e+01 \n",
      "step = 1600 | train loss: 1.88e-04 | test loss 2.12e-04 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 2.11e+01 \n",
      "step = 1800 | train loss: 1.45e-04 | test loss 1.64e-04 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 2.15e+01 \n",
      "step = 2000 | train loss: 1.14e-04 | test loss 1.30e-04 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 2.18e+01 \n",
      "step = 2200 | train loss: 9.18e-05 | test loss 1.04e-04 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 2.21e+01 \n",
      "step = 2400 | train loss: 7.48e-05 | test loss 8.49e-05 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 2.24e+01 \n",
      "step = 2600 | train loss: 6.17e-05 | test loss 7.00e-05 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 2.27e+01 \n",
      "step = 2800 | train loss: 5.14e-05 | test loss 5.83e-05 | train acc: 1.00e+00 | test acc: 1.00e+00 | reg: 2.29e+01 \n"
     ]
    }
   ],
   "source": [
    "### Training ###\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.0)\n",
    "steps = 3000\n",
    "log = 200\n",
    "lamb = 0e-4\n",
    "\n",
    "for step in range(steps):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pred_train = model(inputs_train)\n",
    "    loss_train = torch.mean((pred_train-labels_train)**2)\n",
    "    acc_train = 1-loss_train\n",
    "\n",
    "    pred_test = model(inputs_test)\n",
    "    loss_test = torch.mean((pred_test-labels_test)**2)\n",
    "    acc_test = 1-loss_test\n",
    "    \n",
    "    reg = l1(model)\n",
    "    loss = loss_train + lamb * reg\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % log == 0:\n",
    "        print(\"step = %d | train loss: %.2e | test loss %.2e | train acc: %.2e | test acc: %.2e | reg: %.2e \"%(step, loss_train.cpu().detach().numpy(), loss_test.cpu().detach().numpy(), acc_train.cpu().detach().numpy(), acc_test.cpu().detach().numpy(), reg.cpu().detach().numpy()))\n",
    "    \n",
    "torch.save(model.state_dict(), './model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9cc878d1-61c6-422a-9be0-cea37566d051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (Wh): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (Wx): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (Wy): Linear(in_features=2, out_features=1, bias=True)\n",
       "  (act): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "41384b2d-fb8b-4194-948d-be8b5503e7ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs=inputs_train\n",
    "labels = labels_train\n",
    "seq_length=inputs_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "59ce2df1-a53d-4c3b-9a27-491e7abd0cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = inputs.shape[0]\n",
    "hidden = torch.zeros(batch_size, model.hidden_dim).to(device)\n",
    "hiddens = []\n",
    "\n",
    "for i in range(seq_length):\n",
    "    hidden = model.act(model.Wh(hidden) + model.Wx(inputs[:,i,:]))\n",
    "    out = model.Wy(hidden)\n",
    "    hiddens.append(hidden.clone().cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1e56a08e-37df-4066-8de6-6221ad452449",
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddens = np.transpose(np.array(hiddens), (1,0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c353b338-3805-4654-85d3-6316671e4272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(819, 1, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiddens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "99b549d6-395a-46a4-92a0-04b279555d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fd51b55fd00>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "\n",
    "x = hiddens[:,:,0].reshape(-1,)\n",
    "y = hiddens[:,:,1].reshape(-1,)\n",
    "\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15aff584-1b54-49aa-993e-db451ca998eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "X = np.transpose(np.array([x,y]))\n",
    "kmeans = KMeans(n_clusters=4, random_state=0, n_init=\"auto\").fit(X)\n",
    "vectorlist = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2fac2fa2-0c97-4298-86ed-9310c82298a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98128426, 0.9940553 ],\n",
       "       [0.72525775, 0.31810892],\n",
       "       [0.9990912 , 0.99998164],\n",
       "       [0.98225343, 0.99344057]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "36a945cf-653b-4b3b-85ff-4fc55a30bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find parallelogram\n",
    "\n",
    "# Tries to interpret 2^n vectors as n bits, defining an n-dimensional parallelogram\n",
    "# Max Tegmark Aug 25 2023\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy, itertools\n",
    "\n",
    "\n",
    "def bitstring2int(s): return int(s,2)\n",
    "\n",
    "def int2bitstring(n,i): \n",
    "    s = bin(i)[2:]\n",
    "    return \"\".join([\"0\" for j in range(n-len(s))])+s\n",
    "\n",
    "def str2int(lst): return list(map(int,lst))\n",
    "\n",
    "# Computes all 2^n bitstrings f length n:\n",
    "def allstrings(n): [int2bitstring(n,i) for i in range(2**n)]\n",
    "\n",
    "# Computes B-matrix whose rows are all 2^n bit strings of length n:\n",
    "def Bmatrix(n): \n",
    "    return np.array([str2int(list(int2bitstring(n,i))) for i in range(2**n)])\n",
    "\n",
    "def list2nN(lst):\n",
    "    N = len(lst)\n",
    "    n = int(np.log(N)/np.log(2))\n",
    "    if 2**n != N: \n",
    "        print(\"List length not power of 2: \",f,N,n)\n",
    "        exit()\n",
    "    return n,N                \n",
    "\n",
    "# Input:   a list of 2^n vectors\n",
    "# Output:  fitting error to model where these vectors form an n-dimensional parallelogram in canonical order\n",
    "# Demo:  vectorlist =[[10,20],[10,22],[11,21],[11,23]]\n",
    "def parallelogramFit(vectorlist):\n",
    "    n,N = list2nN(vectorlist)\n",
    "    A = np.array(vectorlist)\n",
    "    A = A - A[0] # WLOG 1st point is at the origin\n",
    "    B = Bmatrix(n)\n",
    "    BtB = B.T @ B\n",
    "    BBinv = np.linalg.inv(BtB)\n",
    "    X = BBinv @ B.T @ A\n",
    "    E = A - B @ X # Fitting error\n",
    "    error = np.trace(E.T @ E)/np.trace(A.T @ A) # Between & 1, where 0 = perfect\n",
    "    return error\n",
    "\n",
    "\n",
    "# Input:   a list of 2^n vectors\n",
    "# Output:  a list of 2^b bitstring of length n, labeling these vectors\n",
    "# Demo:  vectorlist =[[10,20],[10,22],[11,21],[11,23]]\n",
    "# Calls parallelogramFit for all permutations of the vectors and returns best fit.\n",
    "\n",
    "# Computes inverse permutation:\n",
    "def invperm(perm):\n",
    "    n = len(perm)\n",
    "    p = [0 for i in range(n)]\n",
    "    for i in range(n): p[perm[i]]=i\n",
    "    return p\n",
    "# Demo: invperm([1,2,3,0])\n",
    "\n",
    "def vecs2bits(vectorlist):\n",
    "    n,N = list2nN(vectorlist)\n",
    "    perms = list(itertools.permutations(range(N)))\n",
    "    besterror = 666.\n",
    "    for perm in itertools.permutations(range(N)):\n",
    "        A = [vectorlist[i] for i in perm]\n",
    "        error = parallelogramFit(A)\n",
    "        #print(perm,error)\n",
    "        if error < besterror:\n",
    "            error = besterror\n",
    "            bestperm = perm\n",
    "    B = Bmatrix(n)\n",
    "    p = invperm(bestperm)\n",
    "    bestB = np.array([B[p[i]] for i in range(N)]).astype(int)\n",
    "    return bestB,besterror\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0549d5b3-870a-443e-9cb5-07cc04dc07df",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_bits = 1 - vecs2bits(vectorlist.tolist())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dcae2574-a7a1-4bc2-8b30-3a05f7f60f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(2**4)\n",
    "\n",
    "rs = []\n",
    "\n",
    "for i in range(4):\n",
    "    x, r = np.divmod(x, 2)\n",
    "    rs.append(r)\n",
    "    \n",
    "rs = np.transpose(np.array(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d379a6a6-3dce-4a57-8ff3-a7b43b090840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [1, 1, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [1, 0, 1, 0],\n",
       "       [0, 1, 1, 0],\n",
       "       [1, 1, 1, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [1, 0, 0, 1],\n",
       "       [0, 1, 0, 1],\n",
       "       [1, 1, 0, 1],\n",
       "       [0, 0, 1, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [0, 1, 1, 1],\n",
       "       [1, 1, 1, 1]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6970f827-0005-4ffa-b823-eee1d669517e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a2cf372a-6b3f-4873-9def-21a5a3032af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98128426, 0.9940553 ],\n",
       "       [0.72525775, 0.31810892],\n",
       "       [0.9990912 , 0.99998164],\n",
       "       [0.98225343, 0.99344057]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f938824c-9178-461c-a9a8-d395ca91679c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.98128426 0.9940553 ]\n",
      " [0.9990912  0.99998164]\n",
      " [0.72525775 0.31810892]\n",
      " [0.98225343 0.99344057]\n",
      " [0.98128426 0.9940553 ]\n",
      " [0.9990912  0.99998164]\n",
      " [0.72525775 0.31810892]\n",
      " [0.98225343 0.99344057]\n",
      " [0.98128426 0.9940553 ]\n",
      " [0.9990912  0.99998164]\n",
      " [0.72525775 0.31810892]\n",
      " [0.98225343 0.99344057]\n",
      " [0.98128426 0.9940553 ]\n",
      " [0.9990912  0.99998164]\n",
      " [0.72525775 0.31810892]\n",
      " [0.98225343 0.99344057]]\n",
      "[[0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]]\n",
      "torch.Size([16, 2])\n"
     ]
    }
   ],
   "source": [
    "hidden = vectorlist[rs[:,0]*2 + rs[:,1]]\n",
    "print(hidden)\n",
    "x = rs[:,[2,3]]\n",
    "print(x)\n",
    "\n",
    "hidden = torch.tensor(hidden, dtype=torch.float, device=device)\n",
    "x = torch.tensor(x, dtype=torch.float, device=device)\n",
    "print(x.shape)\n",
    "out = model.Wy(hidden)\n",
    "\n",
    "hidden = model.act(model.Wh(hidden) + model.Wx(x))\n",
    "\n",
    "out_bit = np.round(out[:,0].cpu().detach().numpy()).astype(int)\n",
    "\n",
    "hidden_next_bit = cluster_bits[np.argmin(np.linalg.norm(hidden.cpu().detach().numpy()[np.newaxis,:,:] - vectorlist[:,np.newaxis,:], axis=2), axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "88d3f444-d915-48fb-bda0-08de4c358819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "365c5dc0-7d1d-4034-8ce0-da3d5b8e4043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (hidden_current, x_current) => hidden_next; rs => hidden_next_bit\n",
    "# hidden_current = rs[:4, :2] => out_bit = out_bit[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "495a65f6-38e5-48c7-b856-979ee9cd9120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# three symbolic functions to be learned\n",
    "# out from h[0], h[1]\n",
    "# h[0] from last h[0], h[1], current x[0], x[1]\n",
    "# h[1] from last h[0], h[1], current x[0], x[1]\n",
    "\n",
    "\n",
    "# Tools for symbolic regression of boolean functions\n",
    "# Max Tegmark Aug 24-25 2023\n",
    "\n",
    "import time\n",
    "from math import log\n",
    "\n",
    "def bitstring2int(s): return int(s,2)\n",
    "\n",
    "def int2bitstring(n,i): \n",
    "    s = bin(i)[2:]\n",
    "    return \"\".join([\"0\" for j in range(n-len(s))])+s\n",
    "\n",
    "# A boolean function f is defined as a string f of length 2^n, say \"00010001\"\n",
    "# The argument list is defined as a string x length n ,say \"011\"\n",
    "# Returns char \"0\" or \"1\"\n",
    "def booleval(f,x):\n",
    "    n = len(x)\n",
    "    if len(f) != 2**n: \n",
    "        print(\"String length mismatch error: \",n,2**n,len(s))\n",
    "        exit()\n",
    "    i = bitstring2int(x)\n",
    "    return f[i]\n",
    "# DEMO: booleval(\"11111111\",\"111\")\n",
    "\n",
    "# Flip the ith bit in the bitstring n\n",
    "def flip_bit(x,i):\n",
    "    s = list(x)\n",
    "    s[i] = str(1-int(s[i]))\n",
    "    return \"\".join(s)\n",
    "# DEMO: flip_bit(\"11111111\",2)\n",
    "\n",
    "def f2nN(f):\n",
    "    N = len(f)\n",
    "    n = int(log(N)/log(2))\n",
    "    if 2**n != N: \n",
    "        print(\"String length not power of 2: \",f,N,n)\n",
    "        exit()\n",
    "    return n,N\n",
    "\n",
    "def bitsum(s): return sum([int(c) for c in s])\n",
    "\n",
    "def find_variables_used(f):\n",
    "    # Returns e.g. \"101\" if function f depends on x_0 & x_2 but not x_1\n",
    "    n,N = f2nN(f)\n",
    "    s = [\"0\" for i in range(n)]\n",
    "    for i in range(N):\n",
    "        x = int2bitstring(n,i)\n",
    "        for k in range(n):\n",
    "            if booleval(f,x) != booleval(f,flip_bit(x,k)): s[k] = \"1\"\n",
    "    return \"\".join(s)\n",
    "# DEMO: find_variables_used(\"01100110\") # x[1] XOR x[2]\n",
    "\n",
    "# Return the function f restricted to the only variables it depends on:\n",
    "def subfunc(f):\n",
    "    used = find_variables_used(f)\n",
    "    n = len(used)\n",
    "    vars = [i for i in range(n) if used[i]==\"1\"]\n",
    "    n1 = len(vars)\n",
    "    N1 = 2**n1\n",
    "    f1 = [\"0\" for i in range(N1)]\n",
    "    for i in range(N1):\n",
    "        x1 = int2bitstring(n1,i)\n",
    "        x  = [\"0\" for i in range(n)]\n",
    "        for k in range(n1): x[vars[k]] = x1[k]\n",
    "        f1[i] = booleval(f,\"\".join(x))\n",
    "    return f1,vars\n",
    "# DEMO: subfunc(\"01100110\") # x[1] XOR x[2]\n",
    "\n",
    "def parallelogram():\n",
    "    return\n",
    "\n",
    "def symmetricQ(f):\n",
    "    # Check if f is fully symmetric under all permutations of its variables, thus depending only on variable sum\n",
    "    # If so, returns string giving value taken for each bit sum, otherwise returns \"\".\n",
    "    # 2**(n+1) out of the 2**N functions are symmetric.\n",
    "    n,N = f2nN(f)\n",
    "    s = [\"-\" for i in range(n+1)]\n",
    "    for i in range(N):\n",
    "        x = int2bitstring(n,i)\n",
    "        k = bitsum(x)\n",
    "        c = booleval(f,x) \n",
    "        if s[k] != c:\n",
    "            if s[k] == \"-\": s[k] = c\n",
    "            else: return \"\"\n",
    "    return \"\".join(s)\n",
    "\n",
    "# Write x as boolean condition\"\n",
    "def x2dnf(x,varnames):\n",
    "    n = len(x)\n",
    "    return \" and \".join([[\"not \",\"\"][int(x[i])]+varnames[i] for i in range(n)])\n",
    "# Demo: x2dnf(\"110\",\"abc\") \n",
    "# returns \"a and b and not c\"\n",
    "\n",
    "# Write f in disjunctive normal form:\n",
    "def f2dnf(f,varnames):\n",
    "    n,N = f2nN(f)\n",
    "    return \" or \".join([\"(\"+x2dnf(int2bitstring(n,i),varnames)+\")\" for i in range(N) if f[i]==\"1\"])\n",
    "# Demo: f2dnf(\"01100110\",\"abc\") \n",
    "# returns \"a and b and not c\"\n",
    "\n",
    "# Checks if string of type \"010101010\":\n",
    "def parityQ(s):\n",
    "    x = [int(c) for c in s]\n",
    "    if x[0] != 0: return False\n",
    "    for i in range(len(x)-1):\n",
    "        if x[i]+x[i+1] != 1: return False\n",
    "    return True\n",
    "# DEMO: parityQ(\"01010\")\n",
    "    \n",
    "# Checks if string is sorted, like e.g. \"0000111\":\n",
    "def sortedQ(s):\n",
    "    for i in range(len(s)-1):\n",
    "        if s[i]>s[i+1]: return False\n",
    "    return True\n",
    "\n",
    "# Returns 4 if s=\"0000111\", returns -1 if not step function\n",
    "def stepupQ(s):\n",
    "    if not sortedQ(s): return -1\n",
    "    for i in range(len(s)): \n",
    "        if s[i]==\"1\": return i-1\n",
    "    return -1\n",
    "\n",
    "# Returns 4 if s=\"1111000\", returns -1 if not step function\n",
    "def stepdownQ(s):\n",
    "    if not sortedQ(\"\".join(reversed(s))): return -1\n",
    "    for i in range(len(s)): \n",
    "        if s[i]==\"0\": return i-1\n",
    "    return -1\n",
    "\n",
    "def symmfunc(s,varsum):\n",
    "    return \" or \".join([varsum+\"==\"+str(i) for i in range(len(s)) if s[i]==\"1\"])\n",
    "# Demo: symmfunc(\"1001\",\"abc\") \n",
    "# returns \"a+b+c==0 or a+b+c==3\"\n",
    "\n",
    "# Given a string s specifying how function depends on bit sum, return the formula:\n",
    "def symmetric_formula(s,varnames):\n",
    "    if len(varnames)==1 and s==\"10\": return \"not \"+varnames[0]\n",
    "    if parityQ(s): return \" xor \".join(varnames) # f is xor of all variables\n",
    "    varsum = \"+\".join(varnames)\n",
    "    i = stepupQ(s) \n",
    "    if i >= 0: return varsum+\">\"+str(i)\n",
    "    i = stepdownQ(s) \n",
    "    if i >= 0: return varsum+\"<\"+str(i+1)\n",
    "    return symmfunc(s,varsum)\n",
    "\n",
    "def formula(f):\n",
    "    f1,vars = subfunc(f)\n",
    "    varnames = [chr(97+i) for i in vars]\n",
    "    if varnames == []: return str(bool(int(f[0]))) # Function is a constant\n",
    "    formula1 = f2dnf(f1,varnames)\n",
    "    s = symmetricQ(f1)\n",
    "    if s == \"\": return formula1\n",
    "    formula2 = symmetric_formula(s,varnames)\n",
    "    if len(formula2)<len(formula1): formula1 = formula2 # Pick shortest formula\n",
    "    return formula1\n",
    "\n",
    "\n",
    "#def shortest_formula(f):\n",
    "    \n",
    "\n",
    "def demo1():\n",
    "    n = 3\n",
    "    N = 2**n\n",
    "    for i in range(2**N):\n",
    "        f = int2bitstring(N,i)\n",
    "        print(f+\": \"+formula(f))\n",
    "        #time.sleep(.5)\n",
    "    return\n",
    "\n",
    "def demo2():\n",
    "    print(formula(\"00000000\")) # False\n",
    "    print(formula(\"11111111\")) # True\n",
    "    print(formula(\"00001111\")) # a\n",
    "    print(formula(\"01100110\")) # b xor c\n",
    "    print(formula(\"01101001\")) # a xor b xor c\n",
    "    print(formula(\"01111111\")) # a+b+c==1 or a+b+c==2 or a+b+c==3 <=========\n",
    "    print(formula(\"00010111\")) # a+b+c==2 or a+b+c==3\n",
    "    print(formula(\"00000001\")) # a+b+c==3\n",
    "    print(formula(\"11101000\")) # a+b+c==0 or a+b+c==1  FAILS\n",
    "    print(formula(\"10000001\")) # a+b+c==0 or a+b+c==3\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0d3ba085-5fbb-467d-9a2a-c2740825a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (hidden_current, x_current) => hidden_next; rs => hidden_next_bit\n",
    "# hidden_current = rs[:4, :2] => out_bit = out_bit[:4]\n",
    "str_arr = np.zeros(16,dtype=int)\n",
    "indices = np.sum(rs * 2**np.array([3,2,1,0]), axis=1)\n",
    "str_arr[indices] = hidden_next_bit[:,0]\n",
    "string = \"\"\n",
    "for bit in list(str_arr):\n",
    "    string += str(bit)\n",
    "next_a_formula = formula(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7543cab3-4a22-4de9-b182-70d22c1dd0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c+d>0'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_a_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3402df4a-b597-4607-b7fb-f552482b6e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_arr = np.zeros(16,dtype=int)\n",
    "indices = np.sum(rs * 2**np.array([3,2,1,0]), axis=1)\n",
    "str_arr[indices] = hidden_next_bit[:,1]\n",
    "string = \"\"\n",
    "for bit in list(str_arr):\n",
    "    string += str(bit)\n",
    "next_b_formula = formula(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fa640887-269a-4637-88de-da744abbd513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c+d<2'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_b_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "996a04fe-2770-47b3-bb17-8f703139f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output bit\n",
    "str_arr = np.zeros(4,dtype=int)\n",
    "indices = np.sum(rs[:4,:2] * 2**np.array([1,0]), axis=1)\n",
    "str_arr[indices] = out_bit[:4]\n",
    "string = \"\"\n",
    "for bit in list(str_arr):\n",
    "    string += str(bit)\n",
    "out_formula = formula(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6642d052-e4dc-462c-8d97-f9f55b4e3598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(not a and not b) or (a and not b) or (a and b)'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "265c1ef0-3512-4a50-b9d9-d1698eba00db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c+d>0\n",
      "c+d<2\n",
      "(not a and not b) or (a and not b) or (a and b)\n"
     ]
    }
   ],
   "source": [
    "print(next_a_formula)\n",
    "print(next_b_formula)\n",
    "print(out_formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2bb99e0a-8231-4793-8d27-b968ab0a458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "#This is Vedang's version of the code to go from text to python\n",
    "def convert_logical_to_python(logical_expression):\n",
    "    \"\"\"\n",
    "    Converts a logical expression into its equivalent Python representation using NumPy bitwise operators.\n",
    "\n",
    "    Args:\n",
    "        logical_expression (str): The logical expression to be converted.\n",
    "\n",
    "    Returns:\n",
    "        str: The Python representation of the logical expression.\n",
    "    \"\"\"\n",
    "    \n",
    "    #This is the case we have a constraint\n",
    "    if \"<\" in logical_expression or \">\" in logical_expression:\n",
    "        return logical_expression\n",
    "    \n",
    "    def extract_elements(logical_expression):\n",
    "        \"\"\"\n",
    "        Extracts elements enclosed in parentheses from a logical expression.\n",
    "\n",
    "        Args:\n",
    "            logical_expression (str): The logical expression.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of elements inside parentheses.\n",
    "        \"\"\"\n",
    "        inside_elements = re.findall(r'\\((.*?)\\)', logical_expression)\n",
    "        return inside_elements\n",
    "\n",
    "    def apply_not(expression):\n",
    "        \"\"\"\n",
    "        Applies the NOT operation to a given expression.\n",
    "\n",
    "        Args:\n",
    "            expression (str): The expression to be negated.\n",
    "\n",
    "        Returns:\n",
    "            str: The negated expression.\n",
    "        \"\"\"\n",
    "        return f'1 - {expression}'\n",
    "\n",
    "    def convert_logic_operators(formula_split):\n",
    "        \"\"\"\n",
    "        Converts logical operators in a formula split into their equivalent Python representation.\n",
    "\n",
    "        Args:\n",
    "            formula_split (list): The split components of a logical formula.\n",
    "\n",
    "        Returns:\n",
    "            list: The list of converted components.\n",
    "        \"\"\"\n",
    "\n",
    "        operators_mapping = {'or': 'np.bitwise_or', 'and': 'np.bitwise_and', 'xor': 'np.bitwise_xor', 'not': apply_not}\n",
    "\n",
    "        formula_np = []\n",
    "        skip_next = False\n",
    "\n",
    "        for i, sub in enumerate(formula_split):\n",
    "            if skip_next:\n",
    "                skip_next = False\n",
    "                continue\n",
    "\n",
    "            mapped_sub = operators_mapping.get(sub, sub)\n",
    "            if callable(mapped_sub):\n",
    "                mapped_sub = mapped_sub(formula_split[i + 1])\n",
    "                skip_next = True\n",
    "\n",
    "            formula_np.append(mapped_sub)\n",
    "        return formula_np\n",
    "\n",
    "    def build_expression(formula_np):\n",
    "        \"\"\"\n",
    "        Builds a Python expression from a list of converted components.\n",
    "\n",
    "        Args:\n",
    "            formula_np (list): The list of converted components.\n",
    "\n",
    "        Returns:\n",
    "            str: The Python expression.\n",
    "        \"\"\"\n",
    "\n",
    "        expression_str = \"\"\n",
    "        i = 0\n",
    "\n",
    "        while i < len(formula_np):\n",
    "            sub = formula_np[i]\n",
    "\n",
    "            if sub in {'np.bitwise_and', 'np.bitwise_or', 'np.bitwise_xor'}:\n",
    "                expression_str = f'{sub}({expression_str},{formula_np[i+1]})'\n",
    "                i += 2\n",
    "            elif callable(sub):\n",
    "                expression_str = f'{sub}({formula_np[i+1]})'\n",
    "                i += 2\n",
    "            else:\n",
    "                expression_str += sub\n",
    "                i += 1\n",
    "\n",
    "        return expression_str\n",
    "\n",
    "    inside_elements = extract_elements(logical_expression)\n",
    "    to_or = [build_expression(convert_logic_operators(element.split())) for element in inside_elements]\n",
    "    \n",
    "    #If there are no subexpressions in () - we don't have to OR all of them ()\n",
    "    if len(inside_elements) == 0:\n",
    "        return build_expression(convert_logic_operators(logical_expression.split()))\n",
    "\n",
    "    def or_everything(expressions):\n",
    "        \"\"\"\n",
    "        Combines multiple expressions using the NumPy bitwise OR operation.\n",
    "\n",
    "        Args:\n",
    "            expressions (list): List of expressions to be combined.\n",
    "\n",
    "        Returns:\n",
    "            str: The final combined expression.\n",
    "        \"\"\"\n",
    "        if len(expressions) < 2:\n",
    "            return expressions[0]\n",
    "\n",
    "        final_expr = f\"np.bitwise_or({expressions[0]}, {expressions[1]})\"\n",
    "        for i in range(2, len(expressions)):\n",
    "            final_expr = f\"np.bitwise_or({final_expr}, {expressions[i]})\"\n",
    "        return final_expr\n",
    "    return or_everything(to_or)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "47358cf9-6907-430d-b41a-b032a7c724d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_a_formula_str = convert_logical_to_python(next_a_formula)\n",
    "next_b_formula_str = convert_logical_to_python(next_b_formula)\n",
    "out_formula_str = convert_logical_to_python(out_formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7440da37-e0fa-434a-89ea-9c15c040883f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c+d>0\n",
      "c+d<2\n",
      "np.bitwise_or(np.bitwise_or(np.bitwise_and(1 - a,1 - b), np.bitwise_and(a,1 - b)), np.bitwise_and(a,b))\n"
     ]
    }
   ],
   "source": [
    "print(next_a_formula_str)\n",
    "print(next_b_formula_str)\n",
    "print(out_formula_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "94336ba0-9a3e-4efc-8ac7-a6a98a173318",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = inputs.cpu().detach().numpy().astype(int)\n",
    "out_labels = labels.cpu().detach().numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "06871d25-e9ca-4c14-8c8d-538ec10dce21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xs are inputs, with shape (batch size, sequence length, 2)\n",
    "a = np.zeros(xs.shape[0],).astype(int)\n",
    "b = np.zeros(xs.shape[0],).astype(int)\n",
    "outs = []\n",
    "\n",
    "for i in range(xs.shape[1]):\n",
    "    c = xs[:,i,0]\n",
    "    d = xs[:,i,1]\n",
    "\n",
    "    exec('a = ' + next_a_formula_str)\n",
    "    exec('b = ' + next_b_formula_str)\n",
    "    exec('out = ' + out_formula_str)\n",
    "    outs.append(a)\n",
    "\n",
    "outs = np.transpose(np.array(outs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "84cec756-552f-4e20-905a-70821e9204a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_error = np.sum((1-out_labels[:,:,0] == outs))\n",
    "num_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6526451f-e59a-4085-a186-d7fcfec26841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
